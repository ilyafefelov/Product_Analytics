{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "271b33e9",
   "metadata": {},
   "source": [
    "# –î–æ–º–∞—à–Ω—î –∑–∞–≤–¥–∞–Ω–Ω—è ‚Ññ8: –ü—Ä–∏—á–∏–Ω–Ω–æ-–Ω–∞—Å–ª—ñ–¥–∫–æ–≤–∏–π –∞–Ω–∞–ª—ñ–∑ —É –ø—Ä–æ–¥—É–∫—Ç–æ–≤—ñ–π –∞–Ω–∞–ª—ñ—Ç–∏—Ü—ñ\n",
    "\n",
    "## –î–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –≤–ø–ª–∏–≤—É –ø–µ—Ä—Å–æ–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –Ω–∞ —É—Ç—Ä–∏–º–∞–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤\n",
    "\n",
    "**–°—Ç—É–¥–µ–Ω—Ç:** –§–µ—Ñ–µ–ª–æ–≤ –Ü–ª–ª—è  \n",
    "**–î–∏—Å—Ü–∏–ø–ª—ñ–Ω–∞:** –ü—Ä–æ–¥—É–∫—Ç–æ–≤–∞ –∞–Ω–∞–ª—ñ—Ç–∏–∫–∞ —Ç–∞ –ü—Ä–∏–∫–ª–∞–¥–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞  \n",
    "**–î–∞—Ç–∞:** 7 –ª–∏—Å—Ç–æ–ø–∞–¥–∞ 2025\n",
    "\n",
    "---\n",
    "\n",
    "## –ú–µ—Ç–∞ —Ä–æ–±–æ—Ç–∏\n",
    "\n",
    "–û—Ü—ñ–Ω–∏—Ç–∏ –≤–ø–ª–∏–≤ –Ω–æ–≤–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó –ø–µ—Ä—Å–æ–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –Ω–∞ —É—Ç—Ä–∏–º–∞–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤ –º–æ–±—ñ–ª—å–Ω–æ–≥–æ –∑–∞—Å—Ç–æ—Å—É–Ω–∫—É –¥–ª—è –≤–∏–≤—á–µ–Ω–Ω—è –º–æ–≤, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ –º–µ—Ç–æ–¥–∏ –ø—Ä–∏—á–∏–Ω–Ω–æ-–Ω–∞—Å–ª—ñ–¥–∫–æ–≤–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É:\n",
    "\n",
    "1. **–ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∏–π –∞–Ω–∞–ª—ñ–∑** ‚Äî –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∞—Å–æ—Ü—ñ–∞—Ü—ñ—ó –º—ñ–∂ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º —Ñ—É–Ω–∫—Ü—ñ—ó —Ç–∞ —É—Ç—Ä–∏–º–∞–Ω–Ω—è–º\n",
    "2. **Randomized Controlled Trial (RCT)** ‚Äî –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ç–µ—Å—Ç–æ–≤–æ—ó —Ç–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ—ó –≥—Ä—É–ø\n",
    "3. **Propensity Score Matching (PSM)** ‚Äî –∫–æ–Ω—Ç—Ä–æ–ª—å –∑–∞ –∑–º—ñ—à—É–≤–∞—á–∞–º–∏ (confounders) –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ –ø—Ä–∏—á–∏–Ω–Ω–æ–≥–æ –µ—Ñ–µ–∫—Ç—É\n",
    "\n",
    "---\n",
    "\n",
    "## –û–ø–∏—Å –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É\n",
    "\n",
    "- **–¢–µ—Å—Ç–æ–≤–∞ –≥—Ä—É–ø–∞ (Test):** –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ, —è–∫—ñ –æ—Ç—Ä–∏–º–∞–ª–∏ –Ω–æ–≤—É —Ñ—É–Ω–∫—Ü—ñ—é –ø–µ—Ä—Å–æ–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π\n",
    "- **–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞ –≥—Ä—É–ø–∞ (Control):** –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ –±–µ–∑ –Ω–æ–≤–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó\n",
    "- **–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ (outcomes):**\n",
    "  - `Retention_7d`: –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è —á–µ—Ä–µ–∑ 7 –¥–Ω—ñ–≤ –ø—ñ—Å–ª—è —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó (0/1)\n",
    "  - `Retention_30d`: –ü–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è —á–µ—Ä–µ–∑ 30 –¥–Ω—ñ–≤ –ø—ñ—Å–ª—è —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó (0/1)\n",
    "- **–ö–æ–≤–∞—Ä—ñ–∞—Ç–∏ (confounders):**\n",
    "  - `Avg_Session_Time`: –°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å —Å–µ—Å—ñ—ó –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ (—Ö–≤–∏–ª–∏–Ω–∏)\n",
    "  - `Region`: –ì–µ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∏–π —Ä–µ–≥—ñ–æ–Ω (EU, US, Asia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b401384",
   "metadata": {},
   "source": [
    "## –Ü–º–ø–æ—Ä—Ç –±—ñ–±–ª—ñ–æ—Ç–µ–∫ —Ç–∞ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039612bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û—Å–Ω–æ–≤–Ω—ñ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏ –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ –¥–∞–Ω–∏–º–∏\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω—ñ —Ç–µ—Å—Ç–∏ —Ç–∞ –º–æ–¥–µ–ª—ñ\n",
    "from scipy.stats import ttest_ind, pearsonr\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–∏–ª—é –≥—Ä–∞—Ñ—ñ–∫—ñ–≤\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# –§—ñ–∫—Å–∞—Ü—ñ—è random seed –¥–ª—è –≤—ñ–¥—Ç–≤–æ—Ä—é–≤–∞–Ω–æ—Å—Ç—ñ\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì –ë—ñ–±–ª—ñ–æ—Ç–µ–∫–∏ —ñ–º–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ —É—Å–ø—ñ—à–Ω–æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de1416c",
   "metadata": {},
   "source": [
    "## –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa0700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö\n",
    "df = pd.read_csv('user_data_2000.csv')\n",
    "\n",
    "# –ü–µ—Ä–µ–≥–ª—è–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –¥–∞–Ω–∏—Ö\n",
    "print(\"=\"*80)\n",
    "print(\"–°–¢–†–£–ö–¢–£–†–ê –î–ê–ù–ò–•\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n–†–æ–∑–º—ñ—Ä –¥–∞—Ç–∞—Å–µ—Ç—É: {df.shape[0]} —Ä—è–¥–∫—ñ–≤, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫\")\n",
    "print(f\"\\n–ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}\")\n",
    "print(f\"\\n–¢–∏–ø–∏ –¥–∞–Ω–∏—Ö:\\n{df.dtypes}\")\n",
    "print(f\"\\n–ü—Ä–æ–ø—É—â–µ–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è:\\n{df.isnull().sum()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"–ü–ï–†–®–Ü 5 –†–Ø–î–ö–Ü–í\")\n",
    "print(\"=\"*80)\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"–û–ü–ò–°–û–í–ê –°–¢–ê–¢–ò–°–¢–ò–ö–ê\")\n",
    "print(\"=\"*80)\n",
    "print(df.describe())\n",
    "\n",
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"–ö–ê–¢–ï–ì–û–†–Ü–ê–õ–¨–ù–Ü –ó–ú–Ü–ù–ù–Ü\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n–ì—Ä—É–ø–∏ (Group):\")\n",
    "print(df['Group'].value_counts())\n",
    "print(f\"\\n–†–µ–≥—ñ–æ–Ω–∏ (Region):\")\n",
    "print(df['Region'].value_counts())\n",
    "\n",
    "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –±—ñ–Ω–∞—Ä–Ω–æ–≥–æ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ –ª—ñ–∫—É–≤–∞–Ω–Ω—è (treatment)\n",
    "df['Treatment'] = (df['Group'] == 'Test').astype(int)\n",
    "\n",
    "print(\"\\n‚úì –î–∞–Ω—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93644d9b",
   "metadata": {},
   "source": [
    "## –û–ø–∏—Å–æ–≤–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –≥—Ä—É–ø–∞–º–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9def33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–ø–∏—Å–æ–≤–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –≥—Ä—É–ø–∞–º–∏\n",
    "print(\"=\"*80)\n",
    "print(\"–û–ü–ò–°–û–í–ê –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ó–ê –ì–†–£–ü–ê–ú–ò\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# –ì—Ä—É–ø—É–≤–∞–Ω–Ω—è –∑–∞ Group\n",
    "grouped = df.groupby('Group').agg({\n",
    "    'Retention_7d': ['mean', 'std', 'count'],\n",
    "    'Retention_30d': ['mean', 'std', 'count'],\n",
    "    'Avg_Session_Time': ['mean', 'std', 'count']\n",
    "}).round(4)\n",
    "\n",
    "print(\"\\n\", grouped)\n",
    "\n",
    "# –°–µ—Ä–µ–¥–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –¥–ª—è –∫–æ–∂–Ω–æ—ó –º–µ—Ç—Ä–∏–∫–∏\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"–°–ï–†–ï–î–ù–Ü –ó–ù–ê–ß–ï–ù–ù–Ø –£–¢–†–ò–ú–ê–ù–ù–Ø –¢–ê –°–ï–†–ï–î–ù–¨–û–ì–û –ß–ê–°–£ –°–ï–°–Ü–á\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for group in ['Control', 'Test']:\n",
    "    group_data = df[df['Group'] == group]\n",
    "    print(f\"\\n{group} –≥—Ä—É–ø–∞:\")\n",
    "    print(f\"  ‚Ä¢ Retention 7d:  {group_data['Retention_7d'].mean():.2%} (n={len(group_data)})\")\n",
    "    print(f\"  ‚Ä¢ Retention 30d: {group_data['Retention_30d'].mean():.2%}\")\n",
    "    print(f\"  ‚Ä¢ Avg Session Time: {group_data['Avg_Session_Time'].mean():.2f} —Ö–≤ (SD={group_data['Avg_Session_Time'].std():.2f})\")\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–æ–∑–ø–æ–¥—ñ–ª—ñ–≤\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Retention 7d\n",
    "ax1 = axes[0, 0]\n",
    "retention_7d = df.groupby('Group')['Retention_7d'].mean()\n",
    "ax1.bar(retention_7d.index, retention_7d.values, color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "ax1.set_ylabel('–ß–∞—Å—Ç–∫–∞ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤')\n",
    "ax1.set_title('–£—Ç—Ä–∏–º–∞–Ω–Ω—è —á–µ—Ä–µ–∑ 7 –¥–Ω—ñ–≤ –∑–∞ –≥—Ä—É–ø–∞–º–∏')\n",
    "ax1.set_ylim(0, 1)\n",
    "for i, v in enumerate(retention_7d.values):\n",
    "    ax1.text(i, v + 0.02, f'{v:.2%}', ha='center', fontweight='bold')\n",
    "\n",
    "# Retention 30d\n",
    "ax2 = axes[0, 1]\n",
    "retention_30d = df.groupby('Group')['Retention_30d'].mean()\n",
    "ax2.bar(retention_30d.index, retention_30d.values, color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "ax2.set_ylabel('–ß–∞—Å—Ç–∫–∞ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤')\n",
    "ax2.set_title('–£—Ç—Ä–∏–º–∞–Ω–Ω—è —á–µ—Ä–µ–∑ 30 –¥–Ω—ñ–≤ –∑–∞ –≥—Ä—É–ø–∞–º–∏')\n",
    "ax2.set_ylim(0, 1)\n",
    "for i, v in enumerate(retention_30d.values):\n",
    "    ax2.text(i, v + 0.02, f'{v:.2%}', ha='center', fontweight='bold')\n",
    "\n",
    "# Session Time Distribution\n",
    "ax3 = axes[1, 0]\n",
    "df[df['Group'] == 'Control']['Avg_Session_Time'].hist(bins=20, alpha=0.6, label='Control', ax=ax3, color='#3498db')\n",
    "df[df['Group'] == 'Test']['Avg_Session_Time'].hist(bins=20, alpha=0.6, label='Test', ax=ax3, color='#e74c3c')\n",
    "ax3.set_xlabel('–°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å —Å–µ—Å—ñ—ó (—Ö–≤)')\n",
    "ax3.set_ylabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤')\n",
    "ax3.set_title('–†–æ–∑–ø–æ–¥—ñ–ª —Å–µ—Ä–µ–¥–Ω—å–æ–≥–æ —á–∞—Å—É —Å–µ—Å—ñ—ó')\n",
    "ax3.legend()\n",
    "\n",
    "# Region Distribution\n",
    "ax4 = axes[1, 1]\n",
    "region_counts = df.groupby(['Group', 'Region']).size().unstack()\n",
    "region_counts.plot(kind='bar', ax=ax4, color=['#9b59b6', '#f39c12', '#1abc9c'], alpha=0.7)\n",
    "ax4.set_ylabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤')\n",
    "ax4.set_title('–†–æ–∑–ø–æ–¥—ñ–ª –∑–∞ —Ä–µ–≥—ñ–æ–Ω–∞–º–∏')\n",
    "ax4.set_xlabel('–ì—Ä—É–ø–∞')\n",
    "ax4.legend(title='–†–µ–≥—ñ–æ–Ω')\n",
    "ax4.tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì –û–ø–∏—Å–æ–≤—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω–æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09349176",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# –ó–∞–¥–∞—á–∞ ‚Ññ1: –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –º—ñ–∂ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º —Ñ—É–Ω–∫—Ü—ñ—ó —Ç–∞ —É—Ç—Ä–∏–º–∞–Ω–Ω—è–º\n",
    "\n",
    "## –¢–µ–æ—Ä–µ—Ç–∏—á–Ω–∞ –¥–æ–≤—ñ–¥–∫–∞\n",
    "\n",
    "**–ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –ü—ñ—Ä—Å–æ–Ω–∞ (r)** –≤–∏–º—ñ—Ä—é—î –ª—ñ–Ω—ñ–π–Ω–∏–π –∑–≤'—è–∑–æ–∫ –º—ñ–∂ –¥–≤–æ–º–∞ –∑–º—ñ–Ω–Ω–∏–º–∏:\n",
    "\n",
    "$$r = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}}$$\n",
    "\n",
    "**–Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è –∑–Ω–∞—á–µ–Ω—å:**\n",
    "- |r| < 0.1: –¥—É–∂–µ —Å–ª–∞–±–∫–∏–π –∑–≤'—è–∑–æ–∫\n",
    "- 0.1 ‚â§ |r| < 0.3: —Å–ª–∞–±–∫–∏–π –∑–≤'—è–∑–æ–∫\n",
    "- 0.3 ‚â§ |r| < 0.5: –ø–æ–º—ñ—Ä–Ω–∏–π –∑–≤'—è–∑–æ–∫\n",
    "- 0.5 ‚â§ |r| < 0.7: —Å–∏–ª—å–Ω–∏–π –∑–≤'—è–∑–æ–∫\n",
    "- |r| ‚â• 0.7: –¥—É–∂–µ —Å–∏–ª—å–Ω–∏–π –∑–≤'—è–∑–æ–∫\n",
    "\n",
    "**–í–ê–ñ–õ–ò–í–û:** –ö–æ—Ä–µ–ª—è—Ü—ñ—è ‚â† –ü—Ä–∏—á–∏–Ω–Ω—ñ—Å—Ç—å!\n",
    "\n",
    "**–û–±–º–µ–∂–µ–Ω–Ω—è –∫–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É:**\n",
    "1. –ü–æ–∫–∞–∑—É—î –ª–∏—à–µ –∞—Å–æ—Ü—ñ–∞—Ü—ñ—é, –∞ –Ω–µ –ø—Ä–∏—á–∏–Ω–Ω–æ-–Ω–∞—Å–ª—ñ–¥–∫–æ–≤–∏–π –∑–≤'—è–∑–æ–∫\n",
    "2. –ú–æ–∂–µ –±—É—Ç–∏ —Å–ø–æ—Ç–≤–æ—Ä–µ–Ω–∏–π –∑–º—ñ—à—É–≤–∞—á–∞–º–∏ (confounders)\n",
    "3. –ù–µ –≤—Ä–∞—Ö–æ–≤—É—î –Ω–∞–ø—Ä—è–º–æ–∫ –ø—Ä–∏—á–∏–Ω–Ω–æ—Å—Ç—ñ\n",
    "4. –ú–æ–∂–µ –≤–∏—è–≤–ª—è—Ç–∏ –ø–æ–º–∏–ª–∫–æ–≤—ñ –∑–≤'—è–∑–∫–∏ —á–µ—Ä–µ–∑ —Ç—Ä–µ—Ç—é –∑–º—ñ–Ω–Ω—É\n",
    "\n",
    "**–ü—Ä–∏–∫–ª–∞–¥–∏ –∑–º—ñ—à—É–≤–∞—á—ñ–≤:**\n",
    "- –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ –∑ –≤–∏—Å–æ–∫–æ—é –ø–æ—á–∞—Ç–∫–æ–≤–æ—é –∑–∞–ª—É—á–µ–Ω—ñ—Å—Ç—é —á–∞—Å—Ç—ñ—à–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å –Ω–æ–≤—É —Ñ—É–Ω–∫—Ü—ñ—é\n",
    "- –†–µ–≥—ñ–æ–Ω–∞–ª—å–Ω—ñ –≤—ñ–¥–º—ñ–Ω–Ω–æ—Å—Ç—ñ –≤–ø–ª–∏–≤–∞—é—Ç—å —ñ –Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ—ó, —ñ –Ω–∞ —É—Ç—Ä–∏–º–∞–Ω–Ω—è\n",
    "- –î–æ—Å–≤—ñ–¥—á–µ–Ω—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ –º–æ–∂—É—Ç—å –º–∞—Ç–∏ –≤–∏—â—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏ –Ω–µ–∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ñ—É–Ω–∫—Ü—ñ—ó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba807a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–±—á–∏—Å–ª–µ–Ω–Ω—è –∫–æ—Ä–µ–ª—è—Ü—ñ–π –º—ñ–∂ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º —Ñ—É–Ω–∫—Ü—ñ—ó —Ç–∞ —É—Ç—Ä–∏–º–∞–Ω–Ω—è–º\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"–ó–ê–î–ê–ß–ê ‚Ññ1: –ö–û–†–ï–õ–Ø–¶–Ü–ô–ù–ò–ô –ê–ù–ê–õ–Ü–ó\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# –ö–æ—Ä–µ–ª—è—Ü—ñ—è –∑ Retention_7d\n",
    "corr_7d, p_value_7d = pearsonr(df['Treatment'], df['Retention_7d'])\n",
    "\n",
    "print(f\"\\nüìä –ö–æ—Ä–µ–ª—è—Ü—ñ—è –º—ñ–∂ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º —Ñ—É–Ω–∫—Ü—ñ—ó —Ç–∞ Retention_7d:\")\n",
    "print(f\"   –ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –ü—ñ—Ä—Å–æ–Ω–∞: r = {corr_7d:.4f}\")\n",
    "print(f\"   P-value: {p_value_7d:.6f}\")\n",
    "print(f\"   –°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∞ –∑–Ω–∞—á—É—â—ñ—Å—Ç—å: {'–¢–ê–ö (p < 0.05)' if p_value_7d < 0.05 else '–ù–Ü (p ‚â• 0.05)'}\")\n",
    "\n",
    "# –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è —Å–∏–ª–∏ –∑–≤'—è–∑–∫—É\n",
    "if abs(corr_7d) < 0.1:\n",
    "    strength_7d = \"–¥—É–∂–µ —Å–ª–∞–±–∫–∏–π\"\n",
    "elif abs(corr_7d) < 0.3:\n",
    "    strength_7d = \"—Å–ª–∞–±–∫–∏–π\"\n",
    "elif abs(corr_7d) < 0.5:\n",
    "    strength_7d = \"–ø–æ–º—ñ—Ä–Ω–∏–π\"\n",
    "elif abs(corr_7d) < 0.7:\n",
    "    strength_7d = \"—Å–∏–ª—å–Ω–∏–π\"\n",
    "else:\n",
    "    strength_7d = \"–¥—É–∂–µ —Å–∏–ª—å–Ω–∏–π\"\n",
    "\n",
    "direction_7d = \"–ø–æ–∑–∏—Ç–∏–≤–Ω–∏–π\" if corr_7d > 0 else \"–Ω–µ–≥–∞—Ç–∏–≤–Ω–∏–π\"\n",
    "print(f\"   –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è: {strength_7d} {direction_7d} –∑–≤'—è–∑–æ–∫\")\n",
    "\n",
    "# –ö–æ—Ä–µ–ª—è—Ü—ñ—è –∑ Retention_30d\n",
    "corr_30d, p_value_30d = pearsonr(df['Treatment'], df['Retention_30d'])\n",
    "\n",
    "print(f\"\\nüìä –ö–æ—Ä–µ–ª—è—Ü—ñ—è –º—ñ–∂ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º —Ñ—É–Ω–∫—Ü—ñ—ó —Ç–∞ Retention_30d:\")\n",
    "print(f\"   –ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –ü—ñ—Ä—Å–æ–Ω–∞: r = {corr_30d:.4f}\")\n",
    "print(f\"   P-value: {p_value_30d:.6f}\")\n",
    "print(f\"   –°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∞ –∑–Ω–∞—á—É—â—ñ—Å—Ç—å: {'–¢–ê–ö (p < 0.05)' if p_value_30d < 0.05 else '–ù–Ü (p ‚â• 0.05)'}\")\n",
    "\n",
    "# –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è —Å–∏–ª–∏ –∑–≤'—è–∑–∫—É\n",
    "if abs(corr_30d) < 0.1:\n",
    "    strength_30d = \"–¥—É–∂–µ —Å–ª–∞–±–∫–∏–π\"\n",
    "elif abs(corr_30d) < 0.3:\n",
    "    strength_30d = \"—Å–ª–∞–±–∫–∏–π\"\n",
    "elif abs(corr_30d) < 0.5:\n",
    "    strength_30d = \"–ø–æ–º—ñ—Ä–Ω–∏–π\"\n",
    "elif abs(corr_30d) < 0.7:\n",
    "    strength_30d = \"—Å–∏–ª—å–Ω–∏–π\"\n",
    "else:\n",
    "    strength_30d = \"–¥—É–∂–µ —Å–∏–ª—å–Ω–∏–π\"\n",
    "\n",
    "direction_30d = \"–ø–æ–∑–∏—Ç–∏–≤–Ω–∏–π\" if corr_30d > 0 else \"–Ω–µ–≥–∞—Ç–∏–≤–Ω–∏–π\"\n",
    "print(f\"   –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è: {strength_30d} {direction_30d} –∑–≤'—è–∑–æ–∫\")\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–æ—Ä–µ–ª—è—Ü—ñ–π\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatterplot –¥–ª—è Retention_7d\n",
    "ax1 = axes[0]\n",
    "jitter_x = df['Treatment'] + np.random.normal(0, 0.02, size=len(df))\n",
    "jitter_y = df['Retention_7d'] + np.random.normal(0, 0.02, size=len(df))\n",
    "ax1.scatter(jitter_x, jitter_y, alpha=0.3, s=20, color='#3498db')\n",
    "ax1.set_xlabel('–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ—ó (0=Control, 1=Test)')\n",
    "ax1.set_ylabel('Retention 7d (0=–ù—ñ, 1=–¢–∞–∫)')\n",
    "ax1.set_title(f'–ö–æ—Ä–µ–ª—è—Ü—ñ—è: r = {corr_7d:.4f}, p = {p_value_7d:.4f}')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Scatterplot –¥–ª—è Retention_30d\n",
    "ax2 = axes[1]\n",
    "jitter_x = df['Treatment'] + np.random.normal(0, 0.02, size=len(df))\n",
    "jitter_y = df['Retention_30d'] + np.random.normal(0, 0.02, size=len(df))\n",
    "ax2.scatter(jitter_x, jitter_y, alpha=0.3, s=20, color='#e74c3c')\n",
    "ax2.set_xlabel('–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ—ó (0=Control, 1=Test)')\n",
    "ax2.set_ylabel('Retention 30d (0=–ù—ñ, 1=–¢–∞–∫)')\n",
    "ax2.set_title(f'–ö–æ—Ä–µ–ª—è—Ü—ñ—è: r = {corr_30d:.4f}, p = {p_value_30d:.4f}')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"–í–ò–°–ù–û–í–û–ö –ó–ê–î–ê–ß–Ü ‚Ññ1\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "‚ùå –ù–Ü, –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É –ù–ï–ú–û–ñ–õ–ò–í–û –∑—Ä–æ–±–∏—Ç–∏ –≤–∏—Å–Ω–æ–≤–æ–∫ –ø—Ä–æ \n",
    "   –ø—Ä–∏—á–∏–Ω–Ω–æ-–Ω–∞—Å–ª—ñ–¥–∫–æ–≤–∏–π –∑–≤'—è–∑–æ–∫!\n",
    "\n",
    "üîç –ü–†–ò–ß–ò–ù–ò:\n",
    "\n",
    "1. –ü–†–û–ë–õ–ï–ú–ê –ó–í–û–†–û–¢–ù–û–á –ü–†–ò–ß–ò–ù–ù–û–°–¢–Ü\n",
    "   –ö–æ—Ä–µ–ª—è—Ü—ñ—è –Ω–µ –≤–∫–∞–∑—É—î –Ω–∞ –Ω–∞–ø—Ä—è–º–æ–∫ –ø—Ä–∏—á–∏–Ω–Ω–æ—Å—Ç—ñ. –ú–æ–∂–ª–∏–≤–æ:\n",
    "   ‚Ä¢ –§—É–Ω–∫—Ü—ñ—è –≤–ø–ª–∏–≤–∞—î –Ω–∞ —É—Ç—Ä–∏–º–∞–Ω–Ω—è (A ‚Üí B)\n",
    "   ‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ —á–∞—Å—Ç—ñ—à–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å —Ñ—É–Ω–∫—Ü—ñ—é (B ‚Üí A)\n",
    "   ‚Ä¢ –û–±–∏–¥–≤–∞ –Ω–∞–ø—Ä—è–º–∫–∏ –æ–¥–Ω–æ—á–∞—Å–Ω–æ\n",
    "\n",
    "2. –ó–ú–Ü–®–£–í–ê–ß–Ü (CONFOUNDERS)\n",
    "   –¢—Ä–µ—Ç—è –∑–º—ñ–Ω–Ω–∞ –º–æ–∂–µ –≤–ø–ª–∏–≤–∞—Ç–∏ –Ω–∞ –æ–±–∏–¥–≤—ñ:\n",
    "   ‚Ä¢ –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ –∑ –≤–∏—Å–æ–∫–æ—é –ø–æ—á–∞—Ç–∫–æ–≤–æ—é –∑–∞–ª—É—á–µ–Ω—ñ—Å—Ç—é:\n",
    "     - –ß–∞—Å—Ç—ñ—à–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å –Ω–æ–≤—É —Ñ—É–Ω–∫—Ü—ñ—é\n",
    "     - –ú–∞—é—Ç—å –≤–∏—â–µ —É—Ç—Ä–∏–º–∞–Ω–Ω—è –Ω–µ–∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ —Ñ—É–Ω–∫—Ü—ñ—ó\n",
    "   ‚Ä¢ –†–µ–≥—ñ–æ–Ω–∞–ª—å–Ω—ñ —Ñ–∞–∫—Ç–æ—Ä–∏ (Region):\n",
    "     - –í–ø–ª–∏–≤–∞—é—Ç—å –Ω–∞ –ø—Ä–∏–π–Ω—è—Ç—Ç—è –Ω–æ–≤–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó\n",
    "     - –í–ø–ª–∏–≤–∞—é—Ç—å –Ω–∞ —É—Ç—Ä–∏–º–∞–Ω–Ω—è —á–µ—Ä–µ–∑ –∫—É–ª—å—Ç—É—Ä–Ω—ñ –æ—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ\n",
    "   ‚Ä¢ –†—ñ–≤–µ–Ω—å –¥–æ—Å–≤—ñ–¥—É (Avg_Session_Time):\n",
    "     - –î–æ—Å–≤—ñ–¥—á–µ–Ω—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ –∞–∫—Ç–∏–≤–Ω—ñ—à–µ —Ç–µ—Å—Ç—É—é—Ç—å –Ω–æ–≤—ñ —Ñ—É–Ω–∫—Ü—ñ—ó\n",
    "     - –í–æ–Ω–∏ –∂ –º–∞—é—Ç—å –≤–∏—â–µ –±–∞–∑–æ–≤–µ —É—Ç—Ä–∏–º–∞–Ω–Ω—è\n",
    "\n",
    "3. –°–ï–õ–ï–ö–¶–Ü–ô–ù–ï –ó–ú–Ü–©–ï–ù–ù–Ø (SELECTION BIAS)\n",
    "   –Ø–∫—â–æ —Ä–æ–∑–ø–æ–¥—ñ–ª –∑–∞ –≥—Ä—É–ø–∞–º–∏ –Ω–µ –±—É–≤ –≤–∏–ø–∞–¥–∫–æ–≤–∏–º, —Å–ø–æ—Å—Ç–µ—Ä–µ–∂—É–≤–∞–Ω–∞ \n",
    "   –∫–æ—Ä–µ–ª—è—Ü—ñ—è –º–æ–∂–µ –≤—ñ–¥–æ–±—Ä–∞–∂–∞—Ç–∏ –≤—ñ–¥–º—ñ–Ω–Ω–æ—Å—Ç—ñ –º—ñ–∂ –≥—Ä—É–ø–∞–º–∏, –∞ –Ω–µ –µ—Ñ–µ–∫—Ç —Ñ—É–Ω–∫—Ü—ñ—ó.\n",
    "\n",
    "4. –í–Ü–î–°–£–¢–ù–Ü–°–¢–¨ –ö–û–ù–¢–†–û–õ–Æ –ó–ê –ó–ú–Ü–ù–ù–ò–ú–ò\n",
    "   –ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –Ω–µ –∫–æ–Ω—Ç—Ä–æ–ª—é—î –∑–∞ —Å—Ç–æ—Ä–æ–Ω–Ω—ñ–º–∏ —Ñ–∞–∫—Ç–æ—Ä–∞–º–∏,\n",
    "   —è–∫—ñ –º–æ–∂—É—Ç—å –ø–æ—è—Å–Ω—é–≤–∞—Ç–∏ –∑–≤'—è–∑–æ–∫.\n",
    "\n",
    "üí° –î–õ–Ø –í–°–¢–ê–ù–û–í–õ–ï–ù–ù–Ø –ü–†–ò–ß–ò–ù–ù–û–°–¢–Ü –ü–û–¢–†–Ü–ë–ù–Ü:\n",
    "   ‚úì –†–∞–Ω–¥–æ–º—ñ–∑–æ–≤–∞–Ω–∏–π –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç (RCT) ‚Äî –ó–∞–¥–∞—á–∞ ‚Ññ2\n",
    "   ‚úì –ö–æ–Ω—Ç—Ä–æ–ª—å –∑–∞ –∑–º—ñ—à—É–≤–∞—á–∞–º–∏ —á–µ—Ä–µ–∑ PSM ‚Äî –ó–∞–¥–∞—á–∞ ‚Ññ3\n",
    "   ‚úì –Ü–Ω—à—ñ –º–µ—Ç–æ–¥–∏ –ø—Ä–∏—á–∏–Ω–Ω–æ–≥–æ –≤–∏–≤–µ–¥–µ–Ω–Ω—è (DiD, IV, RDD)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f100b67",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# –ó–∞–¥–∞—á–∞ ‚Ññ2: –û—Ü—ñ–Ω–∫–∞ –≤–ø–ª–∏–≤—É —Ñ—É–Ω–∫—Ü—ñ—ó –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é RCT (Randomized Controlled Trial)\n",
    "\n",
    "## –¢–µ–æ—Ä–µ—Ç–∏—á–Ω–∞ –¥–æ–≤—ñ–¥–∫–∞\n",
    "\n",
    "**Randomized Controlled Trial (RCT)** ‚Äî –∑–æ–ª–æ—Ç–∏–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ –ø—Ä–∏—á–∏–Ω–Ω–æ–≥–æ –≤–ø–ª–∏–≤—É.\n",
    "\n",
    "### –ü—Ä–∏–ø—É—â–µ–Ω–Ω—è RCT:\n",
    "1. **–í–∏–ø–∞–¥–∫–æ–≤–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª (Randomization):** –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ –≤–∏–ø–∞–¥–∫–æ–≤–æ –ø—Ä–∏–∑–Ω–∞—á–µ–Ω—ñ –≤ –≥—Ä—É–ø–∏\n",
    "2. **–ù–µ–∑–∞–ª–µ–∂–Ω—ñ—Å—Ç—å –≥—Ä—É–ø:** –ì—Ä—É–ø–∞ –ª—ñ–∫—É–≤–∞–Ω–Ω—è –Ω–µ –≤–ø–ª–∏–≤–∞—î –Ω–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É –≥—Ä—É–ø—É (SUTVA)\n",
    "3. **–î–æ—Ç—Ä–∏–º–∞–Ω–Ω—è –ø—Ä–æ—Ç–æ–∫–æ–ª—É (Compliance):** –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ –æ—Ç—Ä–∏–º—É—é—Ç—å –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–µ –ª—ñ–∫—É–≤–∞–Ω–Ω—è\n",
    "\n",
    "### T-—Ç–µ—Å—Ç –í–µ–ª—á–∞ (Welch's t-test)\n",
    "\n",
    "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Å–µ—Ä–µ–¥–Ω—ñ—Ö –¥–≤–æ—Ö –Ω–µ–∑–∞–ª–µ–∂–Ω–∏—Ö –≥—Ä—É–ø **–±–µ–∑ –ø—Ä–∏–ø—É—â–µ–Ω–Ω—è –ø—Ä–æ —Ä—ñ–≤–Ω—ñ—Å—Ç—å –¥–∏—Å–ø–µ—Ä—Å—ñ–π**.\n",
    "\n",
    "**–§–æ—Ä–º—É–ª–∞:**\n",
    "\n",
    "$$t = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}$$\n",
    "\n",
    "–¥–µ:\n",
    "- $\\bar{X}_1, \\bar{X}_2$ ‚Äî —Å–µ—Ä–µ–¥–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –≥—Ä—É–ø–∞—Ö\n",
    "- $s_1^2, s_2^2$ ‚Äî –≤–∏–±—ñ—Ä–∫–æ–≤—ñ –¥–∏—Å–ø–µ—Ä—Å—ñ—ó\n",
    "- $n_1, n_2$ ‚Äî —Ä–æ–∑–º—ñ—Ä–∏ –≥—Ä—É–ø\n",
    "\n",
    "**–°—Ç—É–ø–µ–Ω—ñ —Å–≤–æ–±–æ–¥–∏ –í–µ–ª—á–∞ (Welch-Satterthwaite):**\n",
    "\n",
    "$$df = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{(s_1^2/n_1)^2}{n_1-1} + \\frac{(s_2^2/n_2)^2}{n_2-1}}$$\n",
    "\n",
    "**–î–æ–≤—ñ—Ä—á–∏–π —ñ–Ω—Ç–µ—Ä–≤–∞–ª (95% CI):**\n",
    "\n",
    "$$CI = (\\bar{X}_1 - \\bar{X}_2) \\pm t_{crit} \\cdot SE$$\n",
    "\n",
    "–¥–µ $SE = \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}$\n",
    "\n",
    "### –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è:\n",
    "- **p-value < 0.05:** –°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ –∑–Ω–∞—á—É—â–∞ —Ä—ñ–∑–Ω–∏—Ü—è –º—ñ–∂ –≥—Ä—É–ø–∞–º–∏\n",
    "- **95% CI –Ω–µ –≤–∫–ª—é—á–∞—î 0:** –ï—Ñ–µ–∫—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ –∑–Ω–∞—á—É—â–∏–π\n",
    "- **–ü—Ä–∞–∫—Ç–∏—á–Ω–∞ –∑–Ω–∞—á—É—â—ñ—Å—Ç—å:** –û—Ü—ñ–Ω—é—î–º–æ —Ä–æ–∑–º—ñ—Ä –µ—Ñ–µ–∫—Ç—É (effect size), –∞ –Ω–µ –ª–∏—à–µ p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151abbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –≥—Ä—É–ø –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é t-—Ç–µ—Å—Ç—É –í–µ–ª—á–∞\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"–ó–ê–î–ê–ß–ê ‚Ññ2: RCT –ê–ù–ê–õ–Ü–ó (T-–¢–ï–°–¢–ò)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è –≥—Ä—É–ø\n",
    "control = df[df['Group'] == 'Control']\n",
    "test = df[df['Group'] == 'Test']\n",
    "\n",
    "# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É 95% –¥–æ–≤—ñ—Ä—á–æ–≥–æ —ñ–Ω—Ç–µ—Ä–≤–∞–ª—É –¥–ª—è —Ä—ñ–∑–Ω–∏—Ü—ñ —Å–µ—Ä–µ–¥–Ω—ñ—Ö\n",
    "def calculate_ci(group1, group2, confidence=0.95):\n",
    "    \"\"\"–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ 95% CI –¥–ª—è —Ä—ñ–∑–Ω–∏—Ü—ñ —Å–µ—Ä–µ–¥–Ω—ñ—Ö (Welch)\"\"\"\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    mean1, mean2 = group1.mean(), group2.mean()\n",
    "    var1, var2 = group1.var(ddof=1), group2.var(ddof=1)\n",
    "    \n",
    "    # Standard error\n",
    "    se = np.sqrt(var1/n1 + var2/n2)\n",
    "    \n",
    "    # –°—Ç—É–ø–µ–Ω—ñ —Å–≤–æ–±–æ–¥–∏ –í–µ–ª—á–∞\n",
    "    df_welch = (var1/n1 + var2/n2)**2 / ((var1/n1)**2/(n1-1) + (var2/n2)**2/(n2-1))\n",
    "    \n",
    "    # –ö—Ä–∏—Ç–∏—á–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è t\n",
    "    from scipy.stats import t as t_dist\n",
    "    t_crit = t_dist.ppf((1 + confidence) / 2, df_welch)\n",
    "    \n",
    "    # –î–æ–≤—ñ—Ä—á–∏–π —ñ–Ω—Ç–µ—Ä–≤–∞–ª\n",
    "    diff = mean1 - mean2\n",
    "    ci_lower = diff - t_crit * se\n",
    "    ci_upper = diff + t_crit * se\n",
    "    \n",
    "    return diff, ci_lower, ci_upper, df_welch\n",
    "\n",
    "# ========== RETENTION 7D ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä RETENTION 7D\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "control_7d = control['Retention_7d']\n",
    "test_7d = test['Retention_7d']\n",
    "\n",
    "# –û–ø–∏—Å–æ–≤–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "print(f\"\\n–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞ –≥—Ä—É–ø–∞:\")\n",
    "print(f\"   –°–µ—Ä–µ–¥–Ω—î: {control_7d.mean():.4f} ({control_7d.mean()*100:.2f}%)\")\n",
    "print(f\"   SD: {control_7d.std():.4f}\")\n",
    "print(f\"   n: {len(control_7d)}\")\n",
    "\n",
    "print(f\"\\n–¢–µ—Å—Ç–æ–≤–∞ –≥—Ä—É–ø–∞:\")\n",
    "print(f\"   –°–µ—Ä–µ–¥–Ω—î: {test_7d.mean():.4f} ({test_7d.mean()*100:.2f}%)\")\n",
    "print(f\"   SD: {test_7d.std():.4f}\")\n",
    "print(f\"   n: {len(test_7d)}\")\n",
    "\n",
    "# T-—Ç–µ—Å—Ç –í–µ–ª—á–∞\n",
    "t_stat_7d, p_value_7d = ttest_ind(test_7d, control_7d, equal_var=False)\n",
    "\n",
    "# –†—ñ–∑–Ω–∏—Ü—è —Ç–∞ –µ—Ñ–µ–∫—Ç\n",
    "diff_7d, ci_lower_7d, ci_upper_7d, df_7d = calculate_ci(test_7d, control_7d)\n",
    "relative_lift_7d = (diff_7d / control_7d.mean()) * 100 if control_7d.mean() != 0 else 0\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*80}\")\n",
    "print(\"–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ t-—Ç–µ—Å—Ç—É –í–µ–ª—á–∞:\")\n",
    "print(f\"{'‚îÄ'*80}\")\n",
    "print(f\"   t-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {t_stat_7d:.4f}\")\n",
    "print(f\"   –°—Ç—É–ø–µ–Ω—ñ —Å–≤–æ–±–æ–¥–∏ (Welch): {df_7d:.2f}\")\n",
    "print(f\"   P-value: {p_value_7d:.6f}\")\n",
    "print(f\"   –°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∞ –∑–Ω–∞—á—É—â—ñ—Å—Ç—å: {'‚úì –¢–ê–ö (p < 0.05)' if p_value_7d < 0.05 else '‚úó –ù–Ü (p ‚â• 0.05)'}\")\n",
    "\n",
    "print(f\"\\n–†—ñ–∑–Ω–∏—Ü—è —Å–µ—Ä–µ–¥–Ω—ñ—Ö (Test - Control):\")\n",
    "print(f\"   –ê–±—Å–æ–ª—é—Ç–Ω–∞: {diff_7d:.4f} ({diff_7d*100:.2f} –ø.–ø.)\")\n",
    "print(f\"   –í—ñ–¥–Ω–æ—Å–Ω–∞: {relative_lift_7d:+.2f}%\")\n",
    "print(f\"   95% CI: [{ci_lower_7d:.4f}, {ci_upper_7d:.4f}]\")\n",
    "print(f\"            [{ci_lower_7d*100:.2f} –ø.–ø., {ci_upper_7d*100:.2f} –ø.–ø.]\")\n",
    "\n",
    "# ========== RETENTION 30D ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä RETENTION 30D\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "control_30d = control['Retention_30d']\n",
    "test_30d = test['Retention_30d']\n",
    "\n",
    "# –û–ø–∏—Å–æ–≤–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "print(f\"\\n–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞ –≥—Ä—É–ø–∞:\")\n",
    "print(f\"   –°–µ—Ä–µ–¥–Ω—î: {control_30d.mean():.4f} ({control_30d.mean()*100:.2f}%)\")\n",
    "print(f\"   SD: {control_30d.std():.4f}\")\n",
    "print(f\"   n: {len(control_30d)}\")\n",
    "\n",
    "print(f\"\\n–¢–µ—Å—Ç–æ–≤–∞ –≥—Ä—É–ø–∞:\")\n",
    "print(f\"   –°–µ—Ä–µ–¥–Ω—î: {test_30d.mean():.4f} ({test_30d.mean()*100:.2f}%)\")\n",
    "print(f\"   SD: {test_30d.std():.4f}\")\n",
    "print(f\"   n: {len(test_30d)}\")\n",
    "\n",
    "# T-—Ç–µ—Å—Ç –í–µ–ª—á–∞\n",
    "t_stat_30d, p_value_30d = ttest_ind(test_30d, control_30d, equal_var=False)\n",
    "\n",
    "# –†—ñ–∑–Ω–∏—Ü—è —Ç–∞ –µ—Ñ–µ–∫—Ç\n",
    "diff_30d, ci_lower_30d, ci_upper_30d, df_30d = calculate_ci(test_30d, control_30d)\n",
    "relative_lift_30d = (diff_30d / control_30d.mean()) * 100 if control_30d.mean() != 0 else 0\n",
    "\n",
    "print(f\"\\n{'‚îÄ'*80}\")\n",
    "print(\"–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ t-—Ç–µ—Å—Ç—É –í–µ–ª—á–∞:\")\n",
    "print(f\"{'‚îÄ'*80}\")\n",
    "print(f\"   t-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {t_stat_30d:.4f}\")\n",
    "print(f\"   –°—Ç—É–ø–µ–Ω—ñ —Å–≤–æ–±–æ–¥–∏ (Welch): {df_30d:.2f}\")\n",
    "print(f\"   P-value: {p_value_30d:.6f}\")\n",
    "print(f\"   –°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∞ –∑–Ω–∞—á—É—â—ñ—Å—Ç—å: {'‚úì –¢–ê–ö (p < 0.05)' if p_value_30d < 0.05 else '‚úó –ù–Ü (p ‚â• 0.05)'}\")\n",
    "\n",
    "print(f\"\\n–†—ñ–∑–Ω–∏—Ü—è —Å–µ—Ä–µ–¥–Ω—ñ—Ö (Test - Control):\")\n",
    "print(f\"   –ê–±—Å–æ–ª—é—Ç–Ω–∞: {diff_30d:.4f} ({diff_30d*100:.2f} –ø.–ø.)\")\n",
    "print(f\"   –í—ñ–¥–Ω–æ—Å–Ω–∞: {relative_lift_30d:+.2f}%\")\n",
    "print(f\"   95% CI: [{ci_lower_30d:.4f}, {ci_upper_30d:.4f}]\")\n",
    "print(f\"            [{ci_lower_30d*100:.2f} –ø.–ø., {ci_upper_30d*100:.2f} –ø.–ø.]\")\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Retention 7d\n",
    "ax1 = axes[0]\n",
    "means_7d = [control_7d.mean(), test_7d.mean()]\n",
    "errors_7d = [control_7d.std()/np.sqrt(len(control_7d)), test_7d.std()/np.sqrt(len(test_7d))]\n",
    "bars1 = ax1.bar(['Control', 'Test'], means_7d, yerr=errors_7d, \n",
    "                capsize=10, color=['#3498db', '#e74c3c'], alpha=0.7, edgecolor='black')\n",
    "ax1.set_ylabel('Retention Rate (—á–∞—Å—Ç–∫–∞)')\n",
    "ax1.set_title(f'Retention 7d\\np-value = {p_value_7d:.6f}, diff = {diff_7d*100:+.2f} –ø.–ø.')\n",
    "ax1.set_ylim(0, max(means_7d) * 1.3)\n",
    "for i, (bar, val) in enumerate(zip(bars1, means_7d)):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, val + errors_7d[i] + 0.01, \n",
    "             f'{val:.2%}', ha='center', fontweight='bold')\n",
    "\n",
    "# Retention 30d\n",
    "ax2 = axes[1]\n",
    "means_30d = [control_30d.mean(), test_30d.mean()]\n",
    "errors_30d = [control_30d.std()/np.sqrt(len(control_30d)), test_30d.std()/np.sqrt(len(test_30d))]\n",
    "bars2 = ax2.bar(['Control', 'Test'], means_30d, yerr=errors_30d, \n",
    "                capsize=10, color=['#3498db', '#e74c3c'], alpha=0.7, edgecolor='black')\n",
    "ax2.set_ylabel('Retention Rate (—á–∞—Å—Ç–∫–∞)')\n",
    "ax2.set_title(f'Retention 30d\\np-value = {p_value_30d:.6f}, diff = {diff_30d*100:+.2f} –ø.–ø.')\n",
    "ax2.set_ylim(0, max(means_30d) * 1.3)\n",
    "for i, (bar, val) in enumerate(zip(bars2, means_30d)):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, val + errors_30d[i] + 0.01, \n",
    "             f'{val:.2%}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"–í–ò–°–ù–û–í–û–ö –ó–ê–î–ê–ß–Ü ‚Ññ2\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# –§–æ—Ä–º—É–≤–∞–Ω–Ω—è –≤–∏—Å–Ω–æ–≤–∫—É\n",
    "if p_value_7d < 0.05 and p_value_30d < 0.05:\n",
    "    conclusion = \"‚úì –¢–ê–ö, –º–æ–∂–Ω–∞ –≤–ø–µ–≤–Ω–µ–Ω–æ —Å–∫–∞–∑–∞—Ç–∏, —â–æ —Ñ—É–Ω–∫—Ü—ñ—è –ø–æ–∫—Ä–∞—â—É—î —É—Ç—Ä–∏–º–∞–Ω–Ω—è\"\n",
    "    detail = f\"\"\"\n",
    "    \n",
    "‚úÖ –°–¢–ê–¢–ò–°–¢–ò–ß–ù–û –ó–ù–ê–ß–£–©–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò:\n",
    "\n",
    "1. RETENTION 7D:\n",
    "   ‚Ä¢ –¢–µ—Å—Ç–æ–≤–∞ –≥—Ä—É–ø–∞: {test_7d.mean():.2%} vs –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞: {control_7d.mean():.2%}\n",
    "   ‚Ä¢ –ü—Ä–∏—Ä—ñ—Å—Ç: {diff_7d*100:+.2f} –ø.–ø. ({relative_lift_7d:+.2f}%)\n",
    "   ‚Ä¢ P-value: {p_value_7d:.6f} < 0.05 ‚úì\n",
    "   ‚Ä¢ 95% CI: [{ci_lower_7d*100:.2f}, {ci_upper_7d*100:.2f}] –ø.–ø. (–Ω–µ –≤–∫–ª—é—á–∞—î 0)\n",
    "\n",
    "2. RETENTION 30D:\n",
    "   ‚Ä¢ –¢–µ—Å—Ç–æ–≤–∞ –≥—Ä—É–ø–∞: {test_30d.mean():.2%} vs –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞: {control_30d.mean():.2%}\n",
    "   ‚Ä¢ –ü—Ä–∏—Ä—ñ—Å—Ç: {diff_30d*100:+.2f} –ø.–ø. ({relative_lift_30d:+.2f}%)\n",
    "   ‚Ä¢ P-value: {p_value_30d:.6f} < 0.05 ‚úì\n",
    "   ‚Ä¢ 95% CI: [{ci_lower_30d*100:.2f}, {ci_upper_30d*100:.2f}] –ø.–ø. (–Ω–µ –≤–∫–ª—é—á–∞—î 0)\n",
    "\n",
    "üí° –Ü–ù–¢–ï–†–ü–†–ï–¢–ê–¶–Ü–Ø:\n",
    "   ‚Ä¢ –û–±–∏–¥–≤—ñ –º–µ—Ç—Ä–∏–∫–∏ —É—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ –∑–Ω–∞—á—É—â–µ –≤–∏—â—ñ –≤ —Ç–µ—Å—Ç–æ–≤—ñ–π –≥—Ä—É–ø—ñ\n",
    "   ‚Ä¢ –î–æ–≤—ñ—Ä—á—ñ —ñ–Ω—Ç–µ—Ä–≤–∞–ª–∏ –Ω–µ –≤–∫–ª—é—á–∞—é—Ç—å –Ω—É–ª—å ‚Üí –µ—Ñ–µ–∫—Ç –Ω–∞–¥—ñ–π–Ω–∏–π\n",
    "   ‚Ä¢ –ï—Ñ–µ–∫—Ç –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è —è–∫ –∫–æ—Ä–æ—Ç–∫–æ—Å—Ç—Ä–æ–∫–æ–≤–æ (7d), —Ç–∞–∫ —ñ –¥–æ–≤–≥–æ—Å—Ç—Ä–æ–∫–æ–≤–æ (30d)\n",
    "   \n",
    "‚ö†Ô∏è –û–ë–ú–ï–ñ–ï–ù–ù–Ø RCT:\n",
    "   –•–æ—á–∞ RCT —î –∑–æ–ª–æ—Ç–∏–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–º, —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤–∞–ª—ñ–¥–Ω—ñ –ª–∏—à–µ –∑–∞ —É–º–æ–≤–∏:\n",
    "   1. –°–ø—Ä–∞–≤–∂–Ω—å–æ—ó —Ä–∞–Ω–¥–æ–º—ñ–∑–∞—Ü—ñ—ó –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤\n",
    "   2. –í—ñ–¥—Å—É—Ç–Ω–æ—Å—Ç—ñ –∑–∞–±—Ä—É–¥–Ω–µ–Ω–Ω—è –º—ñ–∂ –≥—Ä—É–ø–∞–º–∏ (no spillover)\n",
    "   3. –î–æ—Ç—Ä–∏–º–∞–Ω–Ω—è –ø—Ä–æ—Ç–æ–∫–æ–ª—É –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É (compliance)\n",
    "   \n",
    "   –Ø–∫—â–æ —Ü—ñ —É–º–æ–≤–∏ –ø–æ—Ä—É—à–µ–Ω—ñ, –æ—Ü—ñ–Ω–∫–∞ –º–æ–∂–µ –±—É—Ç–∏ –∑–º—ñ—â–µ–Ω–æ—é.\n",
    "\"\"\"\n",
    "elif p_value_7d < 0.05 or p_value_30d < 0.05:\n",
    "    conclusion = \"‚ö†Ô∏è –ß–ê–°–¢–ö–û–í–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò: –ï—Ñ–µ–∫—Ç –∑–Ω–∞—á—É—â–∏–π –ª–∏—à–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç—É\"\n",
    "    detail = f\"\"\"\n",
    "    \n",
    "‚ö†Ô∏è –ù–ï–û–î–ù–û–ó–ù–ê–ß–ù–Ü –†–ï–ó–£–õ–¨–¢–ê–¢–ò:\n",
    "\n",
    "‚Ä¢ Retention 7d: {'–ó–ù–ê–ß–£–©–ò–ô' if p_value_7d < 0.05 else '–ù–ï –ó–ù–ê–ß–£–©–ò–ô'} (p={p_value_7d:.6f})\n",
    "‚Ä¢ Retention 30d: {'–ó–ù–ê–ß–£–©–ò–ô' if p_value_30d < 0.05 else '–ù–ï –ó–ù–ê–ß–£–©–ò–ô'} (p={p_value_30d:.6f})\n",
    "\n",
    "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:\n",
    "1. –ü—Ä–æ–¥–æ–≤–∂–∏—Ç–∏ —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–ª—è –±—ñ–ª—å—à —Ç—Ä–∏–≤–∞–ª–æ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç—É\n",
    "2. –ó–±—ñ–ª—å—à–∏—Ç–∏ —Ä–æ–∑–º—ñ—Ä –≤–∏–±—ñ—Ä–∫–∏ –¥–ª—è –ø—ñ–¥–≤–∏—â–µ–Ω–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ—ó –ø–æ—Ç—É–∂–Ω–æ—Å—Ç—ñ\n",
    "3. –î–æ—Å–ª—ñ–¥–∏—Ç–∏ –≥–µ—Ç–µ—Ä–æ–≥–µ–Ω–Ω—ñ—Å—Ç—å –µ—Ñ–µ–∫—Ç—É –∑–∞ –ø—ñ–¥–≥—Ä—É–ø–∞–º–∏ (Region, Session Time)\n",
    "\"\"\"\n",
    "else:\n",
    "    conclusion = \"‚úó –ù–Ü, –Ω–µ–º–∞—î —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ –∑–Ω–∞—á—É—â–∏—Ö –¥–æ–∫–∞–∑—ñ–≤ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è —É—Ç—Ä–∏–º–∞–Ω–Ω—è\"\n",
    "    detail = f\"\"\"\n",
    "    \n",
    "‚ùå –í–Ü–î–°–£–¢–ù–Ü–°–¢–¨ –°–¢–ê–¢–ò–°–¢–ò–ß–ù–û–á –ó–ù–ê–ß–£–©–û–°–¢–Ü:\n",
    "\n",
    "‚Ä¢ Retention 7d: p={p_value_7d:.6f} ‚â• 0.05\n",
    "‚Ä¢ Retention 30d: p={p_value_30d:.6f} ‚â• 0.05\n",
    "\n",
    "–ú–æ–∂–ª–∏–≤—ñ –ø—Ä–∏—á–∏–Ω–∏:\n",
    "1. –§—É–Ω–∫—Ü—ñ—è –¥—ñ–π—Å–Ω–æ –Ω–µ –≤–ø–ª–∏–≤–∞—î –Ω–∞ —É—Ç—Ä–∏–º–∞–Ω–Ω—è\n",
    "2. –ï—Ñ–µ–∫—Ç —ñ—Å–Ω—É—î, –∞–ª–µ –∑–∞–Ω–∞–¥—Ç–æ –º–∞–ª–∏–π –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è (–Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–∞ –ø–æ—Ç—É–∂–Ω—ñ—Å—Ç—å)\n",
    "3. –ü–æ—Ç—Ä—ñ–±–µ–Ω –±—ñ–ª—å—à–∏–π —Ä–æ–∑–º—ñ—Ä –≤–∏–±—ñ—Ä–∫–∏\n",
    "4. –ï—Ñ–µ–∫—Ç –ø—Ä–æ—è–≤–ª—è—î—Ç—å—Å—è —Ç—ñ–ª—å–∫–∏ –≤ –ø–µ–≤–Ω–∏—Ö –ø—ñ–¥–≥—Ä—É–ø–∞—Ö (–ø–æ—Ç—Ä—ñ–±–µ–Ω subgroup analysis)\n",
    "\n",
    "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:\n",
    "‚Ä¢ –ü—Ä–æ–≤–µ—Å—Ç–∏ –∞–ø–æ—Å—Ç–µ—Ä—ñ–æ—Ä–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–æ—ó –ø–æ—Ç—É–∂–Ω–æ—Å—Ç—ñ (power analysis)\n",
    "‚Ä¢ –î–æ—Å–ª—ñ–¥–∏—Ç–∏ –≥–µ—Ç–µ—Ä–æ–≥–µ–Ω–Ω—ñ—Å—Ç—å –µ—Ñ–µ–∫—Ç—É\n",
    "‚Ä¢ –†–æ–∑–≥–ª—è–Ω—É—Ç–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ —É—Å–ø—ñ—Ö—É\n",
    "\"\"\"\n",
    "\n",
    "print(conclusion)\n",
    "print(detail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb122eee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# –ó–∞–¥–∞—á–∞ ‚Ññ3: –ú–µ—Ç–æ–¥ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç—ñ –∑–∞ –æ—Ü—ñ–Ω–∫–æ—é —Å—Ö–∏–ª—å–Ω–æ—Å—Ç—ñ (Propensity Score Matching, PSM)\n",
    "\n",
    "## –¢–µ–æ—Ä–µ—Ç–∏—á–Ω–∞ –¥–æ–≤—ñ–¥–∫–∞\n",
    "\n",
    "### –©–æ —Ç–∞–∫–µ PSM?\n",
    "\n",
    "**Propensity Score Matching (PSM)** ‚Äî –º–µ—Ç–æ–¥ –æ—Ü—ñ–Ω–∫–∏ –ø—Ä–∏—á–∏–Ω–Ω–æ–≥–æ –µ—Ñ–µ–∫—Ç—É –≤ –æ–±—Å–µ—Ä–≤–∞—Ü—ñ–π–Ω–∏—Ö –¥–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è—Ö —à–ª—è—Ö–æ–º –∫–æ–Ω—Ç—Ä–æ–ª—é –∑–∞ –∑–º—ñ—à—É–≤–∞—á–∞–º–∏ (confounders).\n",
    "\n",
    "### –û—Å–Ω–æ–≤–Ω–∞ —ñ–¥–µ—è:\n",
    "\n",
    "**–û—Ü—ñ–Ω–∫–∞ —Å—Ö–∏–ª—å–Ω–æ—Å—Ç—ñ (propensity score)** ‚Äî —Ü–µ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –æ—Ç—Ä–∏–º–∞—Ç–∏ –ª—ñ–∫—É–≤–∞–Ω–Ω—è (treatment) –∑–∞ —É–º–æ–≤–∏ —Å–ø–æ—Å—Ç–µ—Ä–µ–∂—É–≤–∞–Ω–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫:\n",
    "\n",
    "$$e(X) = P(T=1 | X)$$\n",
    "\n",
    "–¥–µ:\n",
    "- $T$ ‚Äî —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä –ª—ñ–∫—É–≤–∞–Ω–Ω—è (1 = Test, 0 = Control)\n",
    "- $X$ ‚Äî –≤–µ–∫—Ç–æ—Ä –∫–æ–≤–∞—Ä —ñ–∞—Ç (Avg_Session_Time, Region)\n",
    "\n",
    "### –ß–æ–º—É PSM –ø—Ä–∞—Ü—é—î?\n",
    "\n",
    "**–¢–µ–æ—Ä–µ–º–∞ –±–∞–ª–∞–Ω—Å—É–≤–∞–Ω–Ω—è (Balancing property):**\n",
    "\n",
    "–Ø–∫—â–æ –º–∏ –ø–æ—Ä—ñ–≤–Ω—é—î–º–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤ –∑ –æ–¥–Ω–∞–∫–æ–≤–∏–º–∏ propensity scores, —Ç–æ —Ä–æ–∑–ø–æ–¥—ñ–ª —ó—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ $X$ –±—É–¥–µ –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏–º –º—ñ–∂ –≥—Ä—É–ø–∞–º–∏:\n",
    "\n",
    "$$T \\perp X \\mid e(X)$$\n",
    "\n",
    "–¶–µ –æ–∑–Ω–∞—á–∞—î, —â–æ **–∑–∞ —É–º–æ–≤–∏ –æ–¥–Ω–∞–∫–æ–≤–æ–≥–æ propensity score**, –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è –≤ –≥—Ä—É–ø—É —Å—Ç–∞—î \"—è–∫ –±–∏ –≤–∏–ø–∞–¥–∫–æ–≤–∏–º\" (quasi-randomization).\n",
    "\n",
    "### –ï—Ç–∞–ø–∏ PSM:\n",
    "\n",
    "1. **–û—Ü—ñ–Ω–∫–∞ —Å—Ö–∏–ª—å–Ω–æ—Å—Ç—ñ:** –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è $T \\sim X$\n",
    "2. **–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å–ø—ñ–ª—å–Ω–æ—ó –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ (common support):** –ü–µ—Ä–µ–∫–æ–Ω–∞—Ç–∏—Å—è, —â–æ —î overlapping propensity scores\n",
    "3. **Matching:** –ü—ñ–¥—ñ–±—Ä–∞—Ç–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ treated –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ control –∑ –±–ª–∏–∑—å–∫–∏–º propensity score\n",
    "4. **–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å—É:** –ü–µ—Ä–µ–∫–æ–Ω–∞—Ç–∏—Å—è, —â–æ –∫–æ–≤–∞—Ä —ñ–∞—Ç–∏ –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ –ø—ñ—Å–ª—è matching\n",
    "5. **–û—Ü—ñ–Ω–∫–∞ ATT:** –ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ outcomes —É matched sample\n",
    "\n",
    "### Average Treatment Effect on the Treated (ATT):\n",
    "\n",
    "$$ATT = \\mathbb{E}[Y(1) - Y(0) | T=1]$$\n",
    "\n",
    "–¥–µ:\n",
    "- $Y(1)$ ‚Äî –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—ñ–¥ –ª—ñ–∫—É–≤–∞–Ω–Ω—è–º\n",
    "- $Y(0)$ ‚Äî –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ –ª—ñ–∫—É–≤–∞–Ω–Ω—è\n",
    "\n",
    "ATT –ø–æ–∫–∞–∑—É—î **—Å–µ—Ä–µ–¥–Ω—ñ–π –µ—Ñ–µ–∫—Ç –¥–ª—è —Ç–∏—Ö, —Ö—Ç–æ —Ñ–∞–∫—Ç–∏—á–Ω–æ –æ—Ç—Ä–∏–º–∞–≤ –ª—ñ–∫—É–≤–∞–Ω–Ω—è**.\n",
    "\n",
    "### –ü—Ä–∏–ø—É—â–µ–Ω–Ω—è PSM:\n",
    "\n",
    "1. **Unconfoundedness (CIA - Conditional Independence Assumption):**\n",
    "   $$\\{Y(1), Y(0)\\} \\perp T \\mid X$$\n",
    "   –ó–∞ —É–º–æ–≤–∏ $X$, –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è –≤ –≥—Ä—É–ø—É –Ω–µ –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤.\n",
    "\n",
    "2. **–°–ø—ñ–ª—å–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ (Common support / Overlap):**\n",
    "   $$0 < P(T=1|X) < 1$$\n",
    "   –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–Ω—è $X$ —î –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –±—É—Ç–∏ —è–∫ —É test, —Ç–∞–∫ —ñ –≤ control.\n",
    "\n",
    "3. **SUTVA (Stable Unit Treatment Value Assumption):**\n",
    "   –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –Ω–µ –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ —Ç–æ–≥–æ, –≤ —è–∫—ñ–π –≥—Ä—É–ø—ñ –∑–Ω–∞—Ö–æ–¥—è—Ç—å—Å—è —ñ–Ω—à—ñ.\n",
    "\n",
    "### –ú–µ—Ç–æ–¥–∏ matching:\n",
    "\n",
    "1. **Nearest Neighbor (NN):** –î–ª—è –∫–æ–∂–Ω–æ–≥–æ treated —à—É–∫–∞—î–º–æ –Ω–∞–π–±–ª–∏–∂—á–æ–≥–æ control –∑–∞ propensity\n",
    "2. **Caliper matching:** –Ø–∫ NN, –∞–ª–µ –∑ –æ–±–º–µ–∂–µ–Ω–Ω—è–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó –≤—ñ–¥—Å—Ç–∞–Ω—ñ (caliper)\n",
    "3. **Kernel matching:** –ó–≤–∞–∂–µ–Ω–µ —Å–µ—Ä–µ–¥–Ω—î –≤—Å—ñ—Ö controls –∑ –≤–∞–≥–∞–º–∏, —â–æ –∑–∞–ª–µ–∂–∞—Ç—å –≤—ñ–¥ –≤—ñ–¥—Å—Ç–∞–Ω—ñ\n",
    "\n",
    "–£ —Ü—ñ–π —Ä–æ–±–æ—Ç—ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ **NN matching –∑ caliper**:\n",
    "- Caliper = 0.2 √ó SD(logit(propensity score)) ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –ø–æ—Ä—ñ–≥ (Rosenbaum & Rubin, 1985)\n",
    "- Caliper = 0.05 (fixed) ‚Äî —Ñ—ñ–∫—Å–æ–≤–∞–Ω–∏–π –ø–æ—Ä—ñ–≥ —É probability scale\n",
    "\n",
    "### –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞–Ω–∞ —Ä—ñ–∑–Ω–∏—Ü—è —Å–µ—Ä–µ–¥–Ω—ñ—Ö (SMD):\n",
    "\n",
    "–ú—ñ—Ä–∞ –±–∞–ª–∞–Ω—Å—É –∫–æ–≤–∞—Ä —ñ–∞—Ç –º—ñ–∂ –≥—Ä—É–ø–∞–º–∏:\n",
    "\n",
    "$$SMD = \\frac{\\bar{X}_{test} - \\bar{X}_{control}}{\\sqrt{\\frac{s^2_{test} + s^2_{control}}{2}}}$$\n",
    "\n",
    "**–ü—Ä–∞–≤–∏–ª–æ:** $|SMD| < 0.1$ –≤–∫–∞–∑—É—î –Ω–∞ –¥–æ–±—Ä–∏–π –±–∞–ª–∞–Ω—Å."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37d2ef8",
   "metadata": {},
   "source": [
    "## –ö—Ä–æ–∫ 1: –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∑–Ω–∞–∫ —Ç–∞ –æ—Ü—ñ–Ω–∫–∞ —Å—Ö–∏–ª—å–Ω–æ—Å—Ç—ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa0997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"–ó–ê–î–ê–ß–ê ‚Ññ3: PROPENSITY SCORE MATCHING (PSM)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ========== –ü–Ü–î–ì–û–¢–û–í–ö–ê –û–ó–ù–ê–ö ==========\n",
    "print(\"\\n\" + \"‚îÄ\"*80)\n",
    "print(\"–®–ê–ì 1: –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∑–Ω–∞–∫ –¥–ª—è –º–æ–¥–µ–ª—ñ\")\n",
    "print(\"‚îÄ\"*80)\n",
    "\n",
    "# One-hot encoding –¥–ª—è Region\n",
    "df_psm = df.copy()\n",
    "region_dummies = pd.get_dummies(df_psm['Region'], prefix='Region', drop_first=False)\n",
    "df_psm = pd.concat([df_psm, region_dummies], axis=1)\n",
    "\n",
    "print(f\"\\n–ö–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω—ñ –∑–º—ñ–Ω–Ω—ñ (Region):\")\n",
    "print(f\"  ‚Ä¢ –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó: {df['Region'].unique()}\")\n",
    "print(f\"  ‚Ä¢ Dummy –∑–º—ñ–Ω–Ω—ñ: {region_dummies.columns.tolist()}\")\n",
    "\n",
    "# –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü—ñ—è Avg_Session_Time\n",
    "scaler = StandardScaler()\n",
    "df_psm['Session_Time_Scaled'] = scaler.fit_transform(df_psm[['Avg_Session_Time']])\n",
    "\n",
    "print(f\"\\n–ß–∏—Å–ª–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞ (Avg_Session_Time):\")\n",
    "print(f\"  ‚Ä¢ –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∞: mean={df_psm['Avg_Session_Time'].mean():.2f}, std={df_psm['Avg_Session_Time'].std():.2f}\")\n",
    "print(f\"  ‚Ä¢ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞–Ω–∞: mean={df_psm['Session_Time_Scaled'].mean():.4f}, std={df_psm['Session_Time_Scaled'].std():.4f}\")\n",
    "\n",
    "# –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–∞—Ç—Ä–∏—Ü—ñ X –¥–ª—è –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó\n",
    "feature_cols = ['Session_Time_Scaled', 'Region_Asia', 'Region_EU', 'Region_US']\n",
    "X = df_psm[feature_cols].values\n",
    "y = df_psm['Treatment'].values\n",
    "\n",
    "print(f\"\\n–ú–∞—Ç—Ä–∏—Ü—è –æ–∑–Ω–∞–∫ X:\")\n",
    "print(f\"  ‚Ä¢ –†–æ–∑–º—ñ—Ä: {X.shape}\")\n",
    "print(f\"  ‚Ä¢ –û–∑–Ω–∞–∫–∏: {feature_cols}\")\n",
    "\n",
    "# ========== –õ–û–ì–Ü–°–¢–ò–ß–ù–ê –†–ï–ì–†–ï–°–Ü–Ø ==========\n",
    "print(\"\\n\" + \"‚îÄ\"*80)\n",
    "print(\"–®–ê–ì 2: –û—Ü—ñ–Ω–∫–∞ propensity scores –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó\")\n",
    "print(\"‚îÄ\"*80)\n",
    "\n",
    "# –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ propensity score\n",
    "logit_model = LogisticRegression(random_state=42, max_iter=1000, solver='lbfgs')\n",
    "logit_model.fit(X, y)\n",
    "\n",
    "# Propensity scores (–π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –±—É—Ç–∏ –≤ Test –≥—Ä—É–ø—ñ)\n",
    "df_psm['propensity_score'] = logit_model.predict_proba(X)[:, 1]\n",
    "\n",
    "print(f\"\\n‚úì –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è –ø—ñ–¥—ñ–≥–Ω–∞–Ω–∞\")\n",
    "print(f\"\\n–ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç–∏ –º–æ–¥–µ–ª—ñ:\")\n",
    "print(f\"  ‚Ä¢ Intercept: {logit_model.intercept_[0]:.4f}\")\n",
    "for feat, coef in zip(feature_cols, logit_model.coef_[0]):\n",
    "    print(f\"  ‚Ä¢ {feat}: {coef:+.4f}\")\n",
    "\n",
    "# –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç—ñ–≤ (Odds Ratios)\n",
    "print(f\"\\nOdds Ratios (exp(Œ≤)):\")\n",
    "for feat, coef in zip(feature_cols, logit_model.coef_[0]):\n",
    "    or_val = np.exp(coef)\n",
    "    print(f\"  ‚Ä¢ {feat}: {or_val:.4f} ({'–∑–±—ñ–ª—å—à—É—î' if or_val > 1 else '–∑–º–µ–Ω—à—É—î'} —à–∞–Ω—Å–∏ –Ω–∞ {abs((or_val-1)*100):.2f}%)\")\n",
    "\n",
    "# –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ –º–æ–¥–µ–ª—ñ (AUC-ROC)\n",
    "y_pred_proba = logit_model.predict_proba(X)[:, 1]\n",
    "auc = roc_auc_score(y, y_pred_proba)\n",
    "\n",
    "print(f\"\\n–Ø–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ:\")\n",
    "print(f\"  ‚Ä¢ ROC-AUC: {auc:.4f}\")\n",
    "if auc > 0.7:\n",
    "    quality = \"–≤—ñ–¥–º—ñ–Ω–Ω–∞\"\n",
    "elif auc > 0.6:\n",
    "    quality = \"—Ö–æ—Ä–æ—à–∞\"\n",
    "elif auc > 0.5:\n",
    "    quality = \"–∑–∞–¥–æ–≤—ñ–ª—å–Ω–∞\"\n",
    "else:\n",
    "    quality = \"–ø–æ–≥–∞–Ω–∞\"\n",
    "print(f\"  ‚Ä¢ –Ü–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—è: {quality} –¥–∏—Å–∫—Ä–∏–º—ñ–Ω–∞—Ü—ñ–π–Ω–∞ –∑–¥–∞—Ç–Ω—ñ—Å—Ç—å\")\n",
    "\n",
    "# ========== –ü–ï–†–ï–í–Ü–†–ö–ê –°–ü–Ü–õ–¨–ù–û–á –ü–Ü–î–¢–†–ò–ú–ö–ò ==========\n",
    "print(\"\\n\" + \"‚îÄ\"*80)\n",
    "print(\"–®–ê–ì 3: –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å–ø—ñ–ª—å–Ω–æ—ó –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ (common support)\")\n",
    "print(\"‚îÄ\"*80)\n",
    "\n",
    "ps_test = df_psm[df_psm['Treatment'] == 1]['propensity_score']\n",
    "ps_control = df_psm[df_psm['Treatment'] == 0]['propensity_score']\n",
    "\n",
    "print(f\"\\n–†–æ–∑–ø–æ–¥—ñ–ª propensity scores:\")\n",
    "print(f\"  Test –≥—Ä—É–ø–∞:\")\n",
    "print(f\"    ‚Ä¢ Min: {ps_test.min():.4f}\")\n",
    "print(f\"    ‚Ä¢ Max: {ps_test.max():.4f}\")\n",
    "print(f\"    ‚Ä¢ Mean: {ps_test.mean():.4f}\")\n",
    "print(f\"    ‚Ä¢ Median: {ps_test.median():.4f}\")\n",
    "\n",
    "print(f\"  Control –≥—Ä—É–ø–∞:\")\n",
    "print(f\"    ‚Ä¢ Min: {ps_control.min():.4f}\")\n",
    "print(f\"    ‚Ä¢ Max: {ps_control.max():.4f}\")\n",
    "print(f\"    ‚Ä¢ Mean: {ps_control.mean():.4f}\")\n",
    "print(f\"    ‚Ä¢ Median: {ps_control.median():.4f}\")\n",
    "\n",
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ overlap\n",
    "overlap_min = max(ps_test.min(), ps_control.min())\n",
    "overlap_max = min(ps_test.max(), ps_control.max())\n",
    "\n",
    "print(f\"\\n  –°–ø—ñ–ª—å–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ (overlap):\")\n",
    "print(f\"    ‚Ä¢ –î—ñ–∞–ø–∞–∑–æ–Ω: [{overlap_min:.4f}, {overlap_max:.4f}]\")\n",
    "print(f\"    ‚Ä¢ –®–∏—Ä–∏–Ω–∞: {overlap_max - overlap_min:.4f}\")\n",
    "\n",
    "# –û–±—Ä—ñ–∑–∞–Ω–Ω—è –∑–∞ —Å–ø—ñ–ª—å–Ω–æ—é –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é\n",
    "df_psm['in_support'] = (\n",
    "    (df_psm['propensity_score'] >= overlap_min) & \n",
    "    (df_psm['propensity_score'] <= overlap_max)\n",
    ")\n",
    "n_trimmed = (~df_psm['in_support']).sum()\n",
    "print(f\"    ‚Ä¢ –û–±—Ä—ñ–∑–∞–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤: {n_trimmed} ({n_trimmed/len(df_psm)*100:.2f}%)\")\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è propensity scores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "ax1 = axes[0]\n",
    "ax1.hist(ps_control, bins=30, alpha=0.6, label='Control', color='#3498db', density=True)\n",
    "ax1.hist(ps_test, bins=30, alpha=0.6, label='Test', color='#e74c3c', density=True)\n",
    "ax1.axvline(overlap_min, color='green', linestyle='--', linewidth=2, label=f'Common support')\n",
    "ax1.axvline(overlap_max, color='green', linestyle='--', linewidth=2)\n",
    "ax1.set_xlabel('Propensity Score')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('–†–æ–∑–ø–æ–¥—ñ–ª Propensity Scores –∑–∞ –≥—Ä—É–ø–∞–º–∏')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Boxplot\n",
    "ax2 = axes[1]\n",
    "data_to_plot = [ps_control, ps_test]\n",
    "bp = ax2.boxplot(data_to_plot, labels=['Control', 'Test'], patch_artist=True)\n",
    "bp['boxes'][0].set_facecolor('#3498db')\n",
    "bp['boxes'][1].set_facecolor('#e74c3c')\n",
    "ax2.set_ylabel('Propensity Score')\n",
    "ax2.set_title('Boxplot Propensity Scores')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Propensity scores —Ä–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω–æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02446ec",
   "metadata": {},
   "source": [
    "## –ö—Ä–æ–∫ 2: –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å—É –î–û matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a7ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É SMD (Standardized Mean Difference)\n",
    "def calculate_smd(data, group_col, feature_col):\n",
    "    \"\"\"\n",
    "    –†–æ–∑—Ä–∞—Ö–æ–≤—É—î —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞–Ω—É —Ä—ñ–∑–Ω–∏—Ü—é —Å–µ—Ä–µ–¥–Ω—ñ—Ö (SMD) –º—ñ–∂ –≥—Ä—É–ø–∞–º–∏.\n",
    "    \n",
    "    SMD = (mean_test - mean_control) / pooled_std\n",
    "    \n",
    "    –ü—Ä–∞–≤–∏–ª–æ: |SMD| < 0.1 –≤–∫–∞–∑—É—î –Ω–∞ –¥–æ–±—Ä–∏–π –±–∞–ª–∞–Ω—Å\n",
    "    \"\"\"\n",
    "    test_data = data[data[group_col] == 1][feature_col]\n",
    "    control_data = data[data[group_col] == 0][feature_col]\n",
    "    \n",
    "    mean_test = test_data.mean()\n",
    "    mean_control = control_data.mean()\n",
    "    \n",
    "    var_test = test_data.var(ddof=1)\n",
    "    var_control = control_data.var(ddof=1)\n",
    "    \n",
    "    pooled_std = np.sqrt((var_test + var_control) / 2)\n",
    "    \n",
    "    if pooled_std == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    smd = (mean_test - mean_control) / pooled_std\n",
    "    \n",
    "    return smd\n",
    "\n",
    "# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ –±–∞–ª–∞–Ω—Å—É\n",
    "def create_balance_table(data, group_col, features, stage_name):\n",
    "    \"\"\"–°—Ç–≤–æ—Ä—é—î —Ç–∞–±–ª–∏—Ü—é –±–∞–ª–∞–Ω—Å—É –∫–æ–≤–∞—Ä —ñ–∞—Ç\"\"\"\n",
    "    balance_data = []\n",
    "    \n",
    "    for feat in features:\n",
    "        test_mean = data[data[group_col] == 1][feat].mean()\n",
    "        control_mean = data[data[group_col] == 0][feat].mean()\n",
    "        smd = calculate_smd(data, group_col, feat)\n",
    "        \n",
    "        balance_data.append({\n",
    "            'Feature': feat,\n",
    "            'Test Mean': test_mean,\n",
    "            'Control Mean': control_mean,\n",
    "            'Difference': test_mean - control_mean,\n",
    "            'SMD': smd,\n",
    "            'Balanced': '‚úì' if abs(smd) < 0.1 else '‚úó'\n",
    "        })\n",
    "    \n",
    "    balance_df = pd.DataFrame(balance_data)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"–ë–ê–õ–ê–ù–° –ö–û–í–ê–† –Ü–ê–¢: {stage_name}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    print(balance_df.to_string(index=False))\n",
    "    \n",
    "    n_balanced = (balance_df['SMD'].abs() < 0.1).sum()\n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"–ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–æ: {n_balanced}/{len(features)} –æ–∑–Ω–∞–∫ ({n_balanced/len(features)*100:.1f}%)\")\n",
    "    print(f\"–ù–µ–∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–æ: {len(features) - n_balanced} –æ–∑–Ω–∞–∫ (|SMD| ‚â• 0.1)\")\n",
    "    \n",
    "    return balance_df\n",
    "\n",
    "# –û–∑–Ω–∞–∫–∏ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –±–∞–ª–∞–Ω—Å—É\n",
    "balance_features = ['Avg_Session_Time', 'Region_Asia', 'Region_EU', 'Region_US']\n",
    "\n",
    "# –ë–∞–ª–∞–Ω—Å –î–û matching\n",
    "balance_before = create_balance_table(df_psm[df_psm['in_support']], 'Treatment', balance_features, '–î–û MATCHING')\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è Love Plot (–î–û matching)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "smd_values = balance_before['SMD'].values\n",
    "feature_names = balance_before['Feature'].values\n",
    "\n",
    "colors = ['#e74c3c' if abs(smd) >= 0.1 else '#2ecc71' for smd in smd_values]\n",
    "ax.scatter(smd_values, range(len(feature_names)), c=colors, s=100, alpha=0.7, edgecolors='black')\n",
    "\n",
    "# –ü–æ—Ä–æ–≥–æ–≤—ñ –ª—ñ–Ω—ñ—ó\n",
    "ax.axvline(-0.1, color='gray', linestyle='--', linewidth=1.5, alpha=0.7, label='–ü–æ—Ä—ñ–≥ –±–∞–ª–∞–Ω—Å—É (¬±0.1)')\n",
    "ax.axvline(0.1, color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.axvline(0, color='black', linestyle='-', linewidth=2, alpha=0.5)\n",
    "\n",
    "ax.set_yticks(range(len(feature_names)))\n",
    "ax.set_yticklabels(feature_names)\n",
    "ax.set_xlabel('Standardized Mean Difference (SMD)', fontsize=12)\n",
    "ax.set_title('Love Plot: –ë–∞–ª–∞–Ω—Å –∫–æ–≤–∞—Ä —ñ–∞—Ç –î–û matching', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì –ë–∞–ª–∞–Ω—Å –î–û matching –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37470666",
   "metadata": {},
   "source": [
    "## –ö—Ä–æ–∫ 3: Matching ‚Äî –ü—ñ–¥—Ö—ñ–¥ 1 (Caliper = 0.2 √ó SD of logit(PS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f2eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"–ü–Ü–î–•–Ü–î 1: MATCHING –ó CALIPER = 0.2 √ó SD(logit(PS))\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# –û–±—á–∏—Å–ª–µ–Ω–Ω—è logit propensity score\n",
    "df_psm_matched1 = df_psm[df_psm['in_support']].copy()\n",
    "epsilon = 1e-10  # –©–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ log(0)\n",
    "df_psm_matched1['ps_logit'] = np.log(\n",
    "    (df_psm_matched1['propensity_score'] + epsilon) / \n",
    "    (1 - df_psm_matched1['propensity_score'] + epsilon)\n",
    ")\n",
    "\n",
    "# Caliper –∑–∞ –ø—Ä–∞–≤–∏–ª–æ–º Rosenbaum & Rubin (0.2 √ó SD of logit(PS))\n",
    "logit_std = df_psm_matched1['ps_logit'].std()\n",
    "caliper_logit = 0.2 * logit_std\n",
    "\n",
    "print(f\"\\n–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ caliper:\")\n",
    "print(f\"  ‚Ä¢ SD(logit(PS)): {logit_std:.4f}\")\n",
    "print(f\"  ‚Ä¢ Caliper (0.2 √ó SD): {caliper_logit:.4f} (logit scale)\")\n",
    "\n",
    "# –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è caliper —É probability scale (–Ω–∞–±–ª–∏–∂–µ–Ω–æ)\n",
    "# –î–ª—è –º–∞–ª–∏—Ö –≤—ñ–¥—Å—Ç–∞–Ω–µ–π: Œîlogit ‚âà Œîp / (p(1-p))\n",
    "# –í–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ —Å–µ—Ä–µ–¥–Ω—î p –¥–ª—è –∞–ø—Ä–æ–∫—Å–∏–º–∞—Ü—ñ—ó\n",
    "mean_ps = df_psm_matched1['propensity_score'].mean()\n",
    "caliper_prob_approx = caliper_logit * mean_ps * (1 - mean_ps)\n",
    "print(f\"  ‚Ä¢ Caliper (approx. probability scale): {caliper_prob_approx:.4f}\")\n",
    "\n",
    "# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è nearest neighbor matching –∑ caliper\n",
    "def nearest_neighbor_matching_with_caliper(data, ps_col, treatment_col, caliper):\n",
    "    \"\"\"\n",
    "    1:1 Nearest Neighbor Matching –∑ caliper (–±–µ–∑ –ø–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è).\n",
    "    \n",
    "    –ü–æ–≤–µ—Ä—Ç–∞—î matched control indices –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ treated.\n",
    "    \"\"\"\n",
    "    treated_idx = data[data[treatment_col] == 1].index.tolist()\n",
    "    control_idx = data[data[treatment_col] == 0].index.tolist()\n",
    "    \n",
    "    treated_ps = data.loc[treated_idx, ps_col].values.reshape(-1, 1)\n",
    "    control_ps = data.loc[control_idx, ps_col].values.reshape(-1, 1)\n",
    "    \n",
    "    # NearestNeighbors –¥–ª—è –ø–æ—à—É–∫—É –Ω–∞–π–±–ª–∏–∂—á–∏—Ö —Å—É—Å—ñ–¥—ñ–≤\n",
    "    nn = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "    nn.fit(control_ps)\n",
    "    \n",
    "    distances, indices = nn.kneighbors(treated_ps)\n",
    "    \n",
    "    # –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è caliper\n",
    "    matched_pairs = []\n",
    "    matched_control_idx = set()\n",
    "    \n",
    "    for i, (dist, idx) in enumerate(zip(distances.flatten(), indices.flatten())):\n",
    "        if dist <= caliper and idx not in matched_control_idx:\n",
    "            treated_i = treated_idx[i]\n",
    "            control_i = control_idx[idx]\n",
    "            matched_pairs.append((treated_i, control_i))\n",
    "            matched_control_idx.add(idx)\n",
    "    \n",
    "    return matched_pairs\n",
    "\n",
    "# –í–∏–∫–æ–Ω–∞–Ω–Ω—è matching\n",
    "matched_pairs_1 = nearest_neighbor_matching_with_caliper(\n",
    "    df_psm_matched1, \n",
    "    'ps_logit',  # Matching —É logit scale\n",
    "    'Treatment', \n",
    "    caliper_logit\n",
    ")\n",
    "\n",
    "print(f\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ matching:\")\n",
    "print(f\"  ‚Ä¢ Treated –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤: {(df_psm_matched1['Treatment'] == 1).sum()}\")\n",
    "print(f\"  ‚Ä¢ Control –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤: {(df_psm_matched1['Treatment'] == 0).sum()}\")\n",
    "print(f\"  ‚Ä¢ Matched pairs: {len(matched_pairs_1)}\")\n",
    "print(f\"  ‚Ä¢ Treated retained: {len(matched_pairs_1) / (df_psm_matched1['Treatment'] == 1).sum() * 100:.2f}%\")\n",
    "\n",
    "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è matched dataset\n",
    "matched_treated_idx_1 = [pair[0] for pair in matched_pairs_1]\n",
    "matched_control_idx_1 = [pair[1] for pair in matched_pairs_1]\n",
    "matched_idx_1 = matched_treated_idx_1 + matched_control_idx_1\n",
    "\n",
    "df_matched_1 = df_psm_matched1.loc[matched_idx_1].copy()\n",
    "\n",
    "print(f\"  ‚Ä¢ Matched dataset size: {len(df_matched_1)} ({len(df_matched_1)/len(df_psm_matched1)*100:.2f}% –≤—ñ–¥ common support)\")\n",
    "\n",
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å—É –ü–Ü–°–õ–Ø matching\n",
    "print(\"\\n\" + \"‚îÄ\"*80)\n",
    "balance_after_1 = create_balance_table(df_matched_1, 'Treatment', balance_features, '–ü–Ü–°–õ–Ø MATCHING (Caliper 0.2√óSD)')\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è Love Plot (–î–û vs –ü–Ü–°–õ–Ø)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "smd_before = balance_before['SMD'].values\n",
    "smd_after_1 = balance_after_1['SMD'].values\n",
    "feature_names = balance_before['Feature'].values\n",
    "\n",
    "y_pos = np.arange(len(feature_names))\n",
    "\n",
    "ax.scatter(smd_before, y_pos - 0.1, c='#e74c3c', s=100, alpha=0.7, \n",
    "           edgecolors='black', label='–î–û matching', marker='o')\n",
    "ax.scatter(smd_after_1, y_pos + 0.1, c='#2ecc71', s=100, alpha=0.7, \n",
    "           edgecolors='black', label='–ü–Ü–°–õ–Ø matching (0.2√óSD)', marker='s')\n",
    "\n",
    "# –ü–æ—Ä–æ–≥–æ–≤—ñ –ª—ñ–Ω—ñ—ó\n",
    "ax.axvline(-0.1, color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.axvline(0.1, color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.axvline(0, color='black', linestyle='-', linewidth=2, alpha=0.5)\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(feature_names)\n",
    "ax.set_xlabel('Standardized Mean Difference (SMD)', fontsize=12)\n",
    "ax.set_title('Love Plot: –ë–∞–ª–∞–Ω—Å –î–û —ñ –ü–Ü–°–õ–Ø matching (–ü—ñ–¥—Ö—ñ–¥ 1)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å\n",
    "imbalanced_features_1 = balance_after_1[balance_after_1['SMD'].abs() >= 0.1]['Feature'].tolist()\n",
    "has_imbalance_1 = len(imbalanced_features_1) > 0\n",
    "\n",
    "if has_imbalance_1:\n",
    "    print(f\"\\n‚ö†Ô∏è –£–í–ê–ì–ê: –ó–∞–ª–∏—à–∞—î—Ç—å—Å—è –¥–∏—Å–±–∞–ª–∞–Ω—Å —É {len(imbalanced_features_1)} –æ–∑–Ω–∞–∫–∞—Ö:\")\n",
    "    for feat in imbalanced_features_1:\n",
    "        smd = balance_after_1[balance_after_1['Feature'] == feat]['SMD'].values[0]\n",
    "        print(f\"     ‚Ä¢ {feat}: SMD = {smd:.4f}\")\n",
    "else:\n",
    "    print(f\"\\n‚úì –í—Å—ñ –æ–∑–Ω–∞–∫–∏ –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ (|SMD| < 0.1)\")\n",
    "\n",
    "print(\"\\n‚úì –ü—ñ–¥—Ö—ñ–¥ 1 –≤–∏–∫–æ–Ω–∞–Ω–æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f2ad3c",
   "metadata": {},
   "source": [
    "## –ö—Ä–æ–∫ 4: Matching ‚Äî –ü—ñ–¥—Ö—ñ–¥ 2 (Caliper = 0.05 —Ñ—ñ–∫—Å–æ–≤–∞–Ω–∏–π)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcec0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"–ü–Ü–î–•–Ü–î 2: MATCHING –ó –§–Ü–ö–°–û–í–ê–ù–ò–ú CALIPER = 0.05 (probability scale)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Caliper —É probability scale (—Ñ—ñ–∫—Å–æ–≤–∞–Ω–∏–π)\n",
    "caliper_fixed = 0.05\n",
    "\n",
    "print(f\"\\n–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ caliper:\")\n",
    "print(f\"  ‚Ä¢ Caliper (fixed, probability scale): {caliper_fixed:.4f}\")\n",
    "\n",
    "# –í–∏–∫–æ–Ω–∞–Ω–Ω—è matching —É probability scale\n",
    "matched_pairs_2 = nearest_neighbor_matching_with_caliper(\n",
    "    df_psm_matched1, \n",
    "    'propensity_score',  # Matching —É probability scale\n",
    "    'Treatment', \n",
    "    caliper_fixed\n",
    ")\n",
    "\n",
    "print(f\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ matching:\")\n",
    "print(f\"  ‚Ä¢ Treated –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤: {(df_psm_matched1['Treatment'] == 1).sum()}\")\n",
    "print(f\"  ‚Ä¢ Control –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤: {(df_psm_matched1['Treatment'] == 0).sum()}\")\n",
    "print(f\"  ‚Ä¢ Matched pairs: {len(matched_pairs_2)}\")\n",
    "print(f\"  ‚Ä¢ Treated retained: {len(matched_pairs_2) / (df_psm_matched1['Treatment'] == 1).sum() * 100:.2f}%\")\n",
    "\n",
    "# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è matched dataset\n",
    "matched_treated_idx_2 = [pair[0] for pair in matched_pairs_2]\n",
    "matched_control_idx_2 = [pair[1] for pair in matched_pairs_2]\n",
    "matched_idx_2 = matched_treated_idx_2 + matched_control_idx_2\n",
    "\n",
    "df_matched_2 = df_psm_matched1.loc[matched_idx_2].copy()\n",
    "\n",
    "print(f\"  ‚Ä¢ Matched dataset size: {len(df_matched_2)} ({len(df_matched_2)/len(df_psm_matched1)*100:.2f}% –≤—ñ–¥ common support)\")\n",
    "\n",
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å—É –ü–Ü–°–õ–Ø matching\n",
    "print(\"\\n\" + \"‚îÄ\"*80)\n",
    "balance_after_2 = create_balance_table(df_matched_2, 'Treatment', balance_features, '–ü–Ü–°–õ–Ø MATCHING (Caliper 0.05 fixed)')\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è Love Plot (–î–û vs –ü–Ü–°–õ–Ø - –ü—ñ–¥—Ö—ñ–¥ 2)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "smd_before = balance_before['SMD'].values\n",
    "smd_after_2 = balance_after_2['SMD'].values\n",
    "feature_names = balance_before['Feature'].values\n",
    "\n",
    "y_pos = np.arange(len(feature_names))\n",
    "\n",
    "ax.scatter(smd_before, y_pos - 0.1, c='#e74c3c', s=100, alpha=0.7, \n",
    "           edgecolors='black', label='–î–û matching', marker='o')\n",
    "ax.scatter(smd_after_2, y_pos + 0.1, c='#3498db', s=100, alpha=0.7, \n",
    "           edgecolors='black', label='–ü–Ü–°–õ–Ø matching (0.05 fixed)', marker='s')\n",
    "\n",
    "# –ü–æ—Ä–æ–≥–æ–≤—ñ –ª—ñ–Ω—ñ—ó\n",
    "ax.axvline(-0.1, color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.axvline(0.1, color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.axvline(0, color='black', linestyle='-', linewidth=2, alpha=0.5)\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(feature_names)\n",
    "ax.set_xlabel('Standardized Mean Difference (SMD)', fontsize=12)\n",
    "ax.set_title('Love Plot: –ë–∞–ª–∞–Ω—Å –î–û —ñ –ü–Ü–°–õ–Ø matching (–ü—ñ–¥—Ö—ñ–¥ 2)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å\n",
    "imbalanced_features_2 = balance_after_2[balance_after_2['SMD'].abs() >= 0.1]['Feature'].tolist()\n",
    "has_imbalance_2 = len(imbalanced_features_2) > 0\n",
    "\n",
    "if has_imbalance_2:\n",
    "    print(f\"\\n‚ö†Ô∏è –£–í–ê–ì–ê: –ó–∞–ª–∏—à–∞—î—Ç—å—Å—è –¥–∏—Å–±–∞–ª–∞–Ω—Å —É {len(imbalanced_features_2)} –æ–∑–Ω–∞–∫–∞—Ö:\")\n",
    "    for feat in imbalanced_features_2:\n",
    "        smd = balance_after_2[balance_after_2['Feature'] == feat]['SMD'].values[0]\n",
    "        print(f\"     ‚Ä¢ {feat}: SMD = {smd:.4f}\")\n",
    "else:\n",
    "    print(f\"\\n‚úì –í—Å—ñ –æ–∑–Ω–∞–∫–∏ –∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ (|SMD| < 0.1)\")\n",
    "\n",
    "# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –¥–≤–æ—Ö –ø—ñ–¥—Ö–æ–¥—ñ–≤\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"–ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –î–í–û–• –ü–Ü–î–•–û–î–Ü–í –î–û MATCHING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = {\n",
    "    '–ú–µ—Ç—Ä–∏–∫–∞': [\n",
    "        'Caliper –∑–Ω–∞—á–µ–Ω–Ω—è',\n",
    "        'Caliper scale',\n",
    "        'Matched pairs',\n",
    "        'Treated retained (%)',\n",
    "        'Matched sample size',\n",
    "        '–ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ –æ–∑–Ω–∞–∫–∏',\n",
    "        '–ù–µ–∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω—ñ –æ–∑–Ω–∞–∫–∏'\n",
    "    ],\n",
    "    '–ü—ñ–¥—Ö—ñ–¥ 1 (0.2√óSD)': [\n",
    "        f'{caliper_logit:.4f}',\n",
    "        'logit(PS)',\n",
    "        len(matched_pairs_1),\n",
    "        f\"{len(matched_pairs_1) / (df_psm_matched1['Treatment'] == 1).sum() * 100:.2f}%\",\n",
    "        len(df_matched_1),\n",
    "        f\"{(balance_after_1['SMD'].abs() < 0.1).sum()}/{len(balance_features)}\",\n",
    "        f\"{(balance_after_1['SMD'].abs() >= 0.1).sum()}/{len(balance_features)}\"\n",
    "    ],\n",
    "    '–ü—ñ–¥—Ö—ñ–¥ 2 (0.05 fixed)': [\n",
    "        f'{caliper_fixed:.4f}',\n",
    "        'probability',\n",
    "        len(matched_pairs_2),\n",
    "        f\"{len(matched_pairs_2) / (df_psm_matched1['Treatment'] == 1).sum() * 100:.2f}%\",\n",
    "        len(df_matched_2),\n",
    "        f\"{(balance_after_2['SMD'].abs() < 0.1).sum()}/{len(balance_features)}\",\n",
    "        f\"{(balance_after_2['SMD'].abs() >= 0.1).sum()}/{len(balance_features)}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\", comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n‚úì –ü—ñ–¥—Ö—ñ–¥ 2 –≤–∏–∫–æ–Ω–∞–Ω–æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637c9c39",
   "metadata": {},
   "source": [
    "## –ö—Ä–æ–∫ 5: –û—Ü—ñ–Ω–∫–∞ ATT (Average Treatment Effect on the Treated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9bbe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ ATT –Ω–∞ matched –≤–∏–±—ñ—Ä–∫–∞—Ö\n",
    "def estimate_att_matched(df_matched, outcome_col, treatment_col='Treatment'):\n",
    "    treated = df_matched[df_matched[treatment_col] == 1]\n",
    "    control = df_matched[df_matched[treatment_col] == 0]\n",
    "    \n",
    "    # –°–µ—Ä–µ–¥–Ω—ñ —É matched –≤–∏–±—ñ—Ä—Ü—ñ\n",
    "    mean_treated = treated[outcome_col].mean()\n",
    "    mean_control = control[outcome_col].mean()\n",
    "    \n",
    "    att = mean_treated - mean_control\n",
    "    return att, mean_treated, mean_control\n",
    "\n",
    "# –û–±—á–∏—Å–ª–µ–Ω–Ω—è ATT –¥–ª—è –æ–±–æ—Ö –ø—ñ–¥—Ö–æ–¥—ñ–≤ —Ç–∞ –¥–≤–æ—Ö –º–µ—Ç—Ä–∏–∫\n",
    "results = []\n",
    "\n",
    "for approach_name, df_m in [\n",
    "    ('Matching 0.2√óSD (logit scale)', df_matched_1),\n",
    "    ('Matching 0.05 (prob scale)', df_matched_2)\n",
    "]:\n",
    "    for outcome in ['Retention_7d', 'Retention_30d']:\n",
    "        att, m_t, m_c = estimate_att_matched(df_m, outcome)\n",
    "        results.append({\n",
    "            '–ü—ñ–¥—Ö—ñ–¥': approach_name,\n",
    "            'Outcome': outcome,\n",
    "            'ATT (–ø.–ø.)': att * 100,\n",
    "            'Mean(Test)': m_t,\n",
    "            'Mean(Control)': m_c,\n",
    "            'n_matched': len(df_m)\n",
    "        })\n",
    "\n",
    "att_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ATT –Ω–∞ matched –≤–∏–±—ñ—Ä–∫–∞—Ö (–æ–±–∏–¥–≤–∞ –ø—ñ–¥—Ö–æ–¥–∏)\")\n",
    "print(\"=\"*80)\n",
    "print(att_df.to_string(index=False, formatters={'ATT (–ø.–ø.)': '{:.2f}'.format, 'Mean(Test)': '{:.3f}'.format, 'Mean(Control)': '{:.3f}'.format}))\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è\n",
    "g = sns.catplot(\n",
    "    data=att_df, kind='bar', x='Outcome', y='ATT (–ø.–ø.)', hue='–ü—ñ–¥—Ö—ñ–¥',\n",
    "    palette=['#2ecc71', '#3498db'], height=5, aspect=1.5\n",
    ")\n",
    "g.set_axis_labels('Outcome', 'ATT (–ø.–ø.)')\n",
    "g.fig.suptitle('–û—Ü—ñ–Ω–∫–∞ ATT –¥–ª—è –¥–≤–æ—Ö –ø—ñ–¥—Ö–æ–¥—ñ–≤ matching', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì ATT –æ—Ü—ñ–Ω–µ–Ω–æ –Ω–∞ matched –≤–∏–±—ñ—Ä–∫–∞—Ö\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea0fd5",
   "metadata": {},
   "source": [
    "## –ö—Ä–æ–∫ 6: IPTW –¥–ª—è ATT (–∑–≤–∞–∂—É–≤–∞–Ω–Ω—è –∑–∞ —Å—Ö–∏–ª—å–Ω—ñ—Å—Ç—é) ‚Äî –¥—Ä—É–≥–∏–π –º–µ—Ç–æ–¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4d947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPTW (Inverse Probability of Treatment Weighting) –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ ATT\n",
    "print(\"=\"*80)\n",
    "print(\"IPTW –û–¶–Ü–ù–ö–ê ATT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# –°—Ç–∞–±—ñ–ª—ñ–∑–æ–≤–∞–Ω—ñ –≤–∞–≥–∏ –¥–ª—è ATT: treated=1, control=e/(1-e)\n",
    "ps = df_psm['propensity_score'].values\n",
    "T = df_psm['Treatment'].values\n",
    "\n",
    "weights_att = np.where(T == 1, 1.0, ps / (1 - ps))\n",
    "df_psm['iptw_weight'] = weights_att\n",
    "\n",
    "print(\"\\n–ü–ï–†–ï–í–Ü–†–ö–ê –í–ê–ì (summary):\")\n",
    "print(pd.Series(df_psm['iptw_weight']).describe())\n",
    "\n",
    "# –û–±—Ä—ñ–∑–∞–Ω–Ω—è –≤–∞–≥ (winsorization) –¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ\n",
    "upper_quantile = df_psm['iptw_weight'].quantile(0.99)\n",
    "lower_quantile = df_psm['iptw_weight'].quantile(0.01)\n",
    "df_psm['iptw_weight_winsor'] = df_psm['iptw_weight'].clip(lower=lower_quantile, upper=upper_quantile)\n",
    "\n",
    "print(\"\\n–í–ê–ì–ò –ü–Ü–°–õ–Ø –í–Ü–ù–ó–û–†–ò–ó–ê–¶–Ü–á (summary):\")\n",
    "print(pd.Series(df_psm['iptw_weight_winsor']).describe())\n",
    "\n",
    "# –ó–≤–∞–∂–µ–Ω—ñ —Å–µ—Ä–µ–¥–Ω—ñ –¥–ª—è ATT (Retention_7d, Retention_30d)\n",
    "def weighted_mean(y, w):\n",
    "    return np.sum(y * w) / np.sum(w)\n",
    "\n",
    "att_iptw_results = []\n",
    "for outcome in ['Retention_7d', 'Retention_30d']:\n",
    "    y = df_psm[outcome].values\n",
    "    w = df_psm['iptw_weight_winsor'].values\n",
    "    treated_mask = (T == 1)\n",
    "    control_mask = (T == 0)\n",
    "    \n",
    "    mean_treated_w = weighted_mean(y[treated_mask], w[treated_mask])\n",
    "    mean_control_w = weighted_mean(y[control_mask], w[control_mask])\n",
    "    att_w = mean_treated_w - mean_control_w\n",
    "    \n",
    "    att_iptw_results.append({\n",
    "        'Outcome': outcome,\n",
    "        'ATT_IPTW (–ø.–ø.)': att_w * 100,\n",
    "        'Weighted Mean(Test)': mean_treated_w,\n",
    "        'Weighted Mean(Control)': mean_control_w\n",
    "    })\n",
    "\n",
    "att_iptw_df = pd.DataFrame(att_iptw_results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IPTW ATT –†–ï–ó–£–õ–¨–¢–ê–¢–ò\")\n",
    "print(\"=\"*80)\n",
    "print(att_iptw_df.to_string(index=False, formatters={'ATT_IPTW (–ø.–ø.)': '{:.2f}'.format}))\n",
    "\n",
    "# –ë–∞–ª–∞–Ω—Å –ø—ñ—Å–ª—è IPTW (–∑–≤–∞–∂–µ–Ω–∏–π SMD)\n",
    "print(\"\\n\" + \"‚îÄ\"*80)\n",
    "print(\"–ó–í–ê–ñ–ï–ù–ò–ô –ë–ê–õ–ê–ù–° –ü–Ü–°–õ–Ø IPTW\")\n",
    "print(\"‚îÄ\"*80)\n",
    "\n",
    "weighted_balance_data = []\n",
    "for feat in balance_features:\n",
    "    x = df_psm[feat].values\n",
    "    w_t = df_psm.loc[T == 1, 'iptw_weight_winsor'].values\n",
    "    w_c = df_psm.loc[T == 0, 'iptw_weight_winsor'].values\n",
    "    x_t = df_psm.loc[T == 1, feat].values\n",
    "    x_c = df_psm.loc[T == 0, feat].values\n",
    "    \n",
    "    # –ó–≤–∞–∂–µ–Ω—ñ —Å–µ—Ä–µ–¥–Ω—ñ\n",
    "    mean_t_w = weighted_mean(x_t, w_t)\n",
    "    mean_c_w = weighted_mean(x_c, w_c)\n",
    "    \n",
    "    # –ó–≤–∞–∂–µ–Ω—ñ –¥–∏—Å–ø–µ—Ä—Å—ñ—ó\n",
    "    def weighted_var(values, weights, wm):\n",
    "        return np.sum(weights * (values - wm)**2) / np.sum(weights)\n",
    "    \n",
    "    var_t_w = weighted_var(x_t, w_t, mean_t_w)\n",
    "    var_c_w = weighted_var(x_c, w_c, mean_c_w)\n",
    "    pooled_std_w = np.sqrt((var_t_w + var_c_w) / 2)\n",
    "    \n",
    "    smd_w = 0.0 if pooled_std_w == 0 else (mean_t_w - mean_c_w) / pooled_std_w\n",
    "    \n",
    "    weighted_balance_data.append({\n",
    "        'Feature': feat,\n",
    "        'Weighted Mean(Test)': mean_t_w,\n",
    "        'Weighted Mean(Control)': mean_c_w,\n",
    "        'Weighted SMD': smd_w,\n",
    "        'Balanced (|SMD|<0.1)': '‚úì' if abs(smd_w) < 0.1 else '‚úó'\n",
    "    })\n",
    "\n",
    "weighted_balance_df = pd.DataFrame(weighted_balance_data)\n",
    "print(weighted_balance_df.to_string(index=False, formatters={'Weighted Mean(Test)': '{:.3f}'.format, 'Weighted Mean(Control)': '{:.3f}'.format, 'Weighted SMD': '{:.3f}'.format}))\n",
    "\n",
    "n_balanced_w = (weighted_balance_df['Weighted SMD'].abs() < 0.1).sum()\n",
    "print(f\"\\n–ó–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–æ –æ–∑–Ω–∞–∫ –ø—ñ—Å–ª—è IPTW: {n_balanced_w}/{len(balance_features)}\")\n",
    "\n",
    "# Love Plot –¥–ª—è IPTW\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(weighted_balance_df['Weighted SMD'], np.arange(len(balance_features)), c=['#2ecc71' if abs(s) < 0.1 else '#e74c3c' for s in weighted_balance_df['Weighted SMD']], s=100, edgecolors='black')\n",
    "ax.axvline(-0.1, color='gray', linestyle='--', linewidth=1.5)\n",
    "ax.axvline(0.1, color='gray', linestyle='--', linewidth=1.5)\n",
    "ax.axvline(0, color='black', linestyle='-', linewidth=2)\n",
    "ax.set_yticks(np.arange(len(balance_features)))\n",
    "ax.set_yticklabels(balance_features)\n",
    "ax.set_xlabel('Weighted SMD')\n",
    "ax.set_title('–ó–≤–∞–∂–µ–Ω–∏–π –±–∞–ª–∞–Ω—Å –ø—ñ—Å–ª—è IPTW')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì IPTW –æ—Ü—ñ–Ω–µ–Ω–æ —ñ –±–∞–ª–∞–Ω—Å –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae76bb",
   "metadata": {},
   "source": [
    "## –ö—Ä–æ–∫ 7: –£–º–æ–≤–∞ ‚Äî –¥–æ–¥–∞—Ç–∏ –≤–∑–∞—î–º–æ–¥—ñ—é Region√óSession, —è–∫—â–æ –¥–∏—Å–±–∞–ª–∞–Ω—Å –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9477b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞: —á–∏ –∑–∞–ª–∏—à–∏–≤—Å—è —Å—É—Ç—Ç—î–≤–∏–π –¥–∏—Å–±–∞–ª–∞–Ω—Å –ø—ñ—Å–ª—è matching –∞–±–æ IPTW?\n",
    "needs_interaction = False\n",
    "\n",
    "if 'balance_after_1' in globals() and (balance_after_1['SMD'].abs() >= 0.1).any():\n",
    "    needs_interaction = True\n",
    "if 'balance_after_2' in globals() and (balance_after_2['SMD'].abs() >= 0.1).any():\n",
    "    needs_interaction = True\n",
    "if 'weighted_balance_df' in globals() and (weighted_balance_df['Weighted SMD'].abs() >= 0.1).any():\n",
    "    needs_interaction = True\n",
    "\n",
    "print(f\"\\n–ù–µ–æ–±—Ö—ñ–¥–Ω—ñ—Å—Ç—å –¥–æ–¥–∞–≤–∞–Ω–Ω—è –≤–∑–∞—î–º–æ–¥—ñ—ó Region√óSession: {'–¢–ê–ö' if needs_interaction else '–ù–Ü'}\")\n",
    "\n",
    "if needs_interaction:\n",
    "    print(\"\\n–î–æ–¥–∞—î–º–æ –≤–∑–∞—î–º–æ–¥—ñ—é Region√óSession —É –º–æ–¥–µ–ª—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É (doubly-robust)\")\n",
    "    \n",
    "    # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è —Ä–µ–≥—Ä–µ—Å—ñ—ó (–≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ IPTW-–≤–∞–≥–∏ —è–∫ –±—ñ–ª—å—à –ø–æ–≤–Ω—ñ)\n",
    "    reg_data = df_psm.copy()\n",
    "    reg_data['Region'] = df_psm['Region']\n",
    "    reg_data['Session'] = df_psm['Avg_Session_Time']\n",
    "    \n",
    "    # –ü–æ–±—É–¥–æ–≤–∞ —Ñ–æ—Ä–º—É–ª–∏ –∑ –≤–∑–∞—î–º–æ–¥—ñ—î—é: Y ~ T + Region*Session + Region + Session\n",
    "    # –î–ª—è –±—ñ–Ω–∞—Ä–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –ª—ñ–Ω—ñ–π–Ω—É –π–º–æ–≤—ñ—Ä–Ω—ñ—Å–Ω—É –º–æ–¥–µ–ª—å —è–∫ –ø—Ä–æ—Å—Ç—É —ñ–ª—é—Å—Ç—Ä–∞—Ü—ñ—é (–∞–±–æ GLM binomial)\n",
    "    import statsmodels.formula.api as smf\n",
    "    \n",
    "    for outcome in ['Retention_7d', 'Retention_30d']:\n",
    "        formula = f\"{outcome} ~ Treatment + C(Region) * Session\"\n",
    "        model_wls = smf.wls(formula=formula, data=reg_data, weights=reg_data['iptw_weight_winsor']).fit(cov_type='HC1')\n",
    "        \n",
    "        coef_T = model_wls.params.get('Treatment', np.nan)\n",
    "        p_T = model_wls.pvalues.get('Treatment', np.nan)\n",
    "        ci_T = model_wls.conf_int().loc['Treatment'].values if 'Treatment' in model_wls.params.index else [np.nan, np.nan]\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"–î–í–û–ö–†–û–ö–û–í–ê –û–¶–Ü–ù–ö–ê –ó –í–ó–ê–Ñ–ú–û–î–Ü–Ñ–Æ (Outcome: {outcome})\")\n",
    "        print(\"=\"*80)\n",
    "        print(model_wls.summary().tables[1])\n",
    "        print(f\"\\n–û—Ü—ñ–Ω–∫–∞ –µ—Ñ–µ–∫—Ç—É Treatment (—Å–∫–æ—Ä–∏–≥–æ–≤–∞–Ω–∞): {coef_T:+.4f}\")\n",
    "        print(f\"P-value: {p_T:.6f}\")\n",
    "        print(f\"95% CI: [{ci_T[0]:.4f}, {ci_T[1]:.4f}]\")\n",
    "else:\n",
    "    print(\"\\n–ë–∞–ª–∞–Ω—Å –∑–∞–¥–æ–≤—ñ–ª—å–Ω–∏–π. –î–æ–¥–∞–≤–∞–Ω–Ω—è –≤–∑–∞—î–º–æ–¥—ñ—ó –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–µ.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b9cbc6",
   "metadata": {},
   "source": [
    "## –ö—Ä–æ–∫ 8: –ë—É—Ç—Å—Ç—Ä–∞–ø –î–Ü –¥–ª—è ATT (–æ–±–∏–¥–≤–∞ –º–µ—Ç–æ–¥–∏) ‚Äî –ø–æ—è—Å–Ω–µ–Ω–Ω—è —ñ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ë–£–¢–°–¢–†–ê–ü –î–õ–Ø –û–¶–Ü–ù–ö–ò –ù–ï–ü–ê–†–ê–ú–ï–¢–†–ò–ß–ù–ò–• –î–Ü\n",
    "print(\"=\"*80)\n",
    "print(\"–ë–£–¢–°–¢–†–ê–ü –î–õ–Ø ATT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "–ü–æ—è—Å–Ω–µ–Ω–Ω—è –º–µ—Ç–æ–¥—É:\n",
    "\n",
    "–ë—É—Ç—Å—Ç—Ä–∞–ø ‚Äî —Ü–µ –º–µ—Ç–æ–¥ –Ω–∞–±–ª–∏–∂–µ–Ω–Ω—è —Ä–æ–∑–ø–æ–¥—ñ–ª—É –æ—Ü—ñ–Ω–∫–∏ –∑–∞ —Ä–∞—Ö—É–Ω–æ–∫ –±–∞–≥–∞—Ç–æ—Ä–∞–∑–æ–≤–æ–≥–æ\n",
    "—Ä–µ—Å–µ–º–ø–ª—É–≤–∞–Ω–Ω—è –∑ –≤–∏—Ö—ñ–¥–Ω–æ—ó –≤–∏–±—ñ—Ä–∫–∏ (–∑ –ø–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è–º). –ú–∏ —Ñ–æ—Ä–º—É—î–º–æ –µ–º–ø—ñ—Ä–∏—á–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª\n",
    "ATT —ñ –±–µ—Ä–µ–º–æ percentiles (2.5%, 97.5%) —è–∫ 95% –¥–æ–≤—ñ—Ä—á–∏–π —ñ–Ω—Ç–µ—Ä–≤–∞–ª.\n",
    "\n",
    "–ß–æ–º—É –±—É—Ç—Å—Ç—Ä–∞–ø –ø–æ—Ç—Ä—ñ–±–Ω–∏–π —Ç—É—Ç?\n",
    "‚Ä¢ –§–æ—Ä–º—É–ª–∏ –¥–∏—Å–ø–µ—Ä—Å—ñ—ó –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –æ—Ü—ñ–Ω–æ–∫ (matching, IPTW) –∞–±–æ –Ω–µ—Ç–æ—á–Ω—ñ, –∞–±–æ –≤—ñ–¥—Å—É—Ç–Ω—ñ.\n",
    "‚Ä¢ –ë—É—Ç—Å—Ç—Ä–∞–ø –Ω–µ –ø–æ—Ç—Ä–µ–±—É—î –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–∏—Ö –ø—Ä–∏–ø—É—â–µ–Ω—å –ø—Ä–æ —Ä–æ–∑–ø–æ–¥—ñ–ª –æ—Ü—ñ–Ω–∫–∏.\n",
    "‚Ä¢ –î–∞—î —É–∑–∞–≥–∞–ª—å–Ω–µ–Ω—É –æ—Ü—ñ–Ω–∫—É –Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–æ—Å—Ç—ñ.\n",
    "\n",
    "–û–±–º–µ–∂–µ–Ω–Ω—è:\n",
    "‚Ä¢ –û–±—á–∏—Å–ª—é–≤–∞–ª—å–Ω–æ –∑–∞—Ç—Ä–∞—Ç–Ω–∏–π (B ‚â• 1000 –±–∞–∂–∞–Ω–æ).\n",
    "‚Ä¢ –Ø–∫—â–æ matching –Ω–µ—Å—Ç–∞–±—ñ–ª—å–Ω–∏–π –ø—Ä–∏ —Ä–µ—Å–µ–º–ø–ª—ñ–Ω–≥—É ‚Äî –î–Ü –º–æ–∂—É—Ç—å –±—É—Ç–∏ —à–∏—Ä–æ–∫–∏–º–∏.\n",
    "‚Ä¢ –ù–µ –∫–æ—Ä–∏–≥—É—î —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–Ω–µ –∑–º—ñ—â–µ–Ω–Ω—è (bias), –ª–∏—à–µ –¥–∞—î –≤–∞—Ä—ñ–∞–±–µ–ª—å–Ω—ñ—Å—Ç—å.\n",
    "\"\"\")\n",
    "\n",
    "# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∫—ñ–ª—å–∫–æ—Å—Ç—ñ —ñ—Ç–µ—Ä–∞—Ü—ñ–π –±—É—Ç—Å—Ç—Ä–∞–ø—É\n",
    "B = 300  # –î–ª—è –¥–æ–º–∞—à–Ω—å–æ—ó —Ä–æ–±–æ—Ç–∏ –æ–±–º–µ–∂–∏–º–æ –¥–æ 300 (–º–æ–∂–Ω–∞ 1000 –ø—Ä–∏ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ–º—É —á–∞—Å—ñ)\n",
    "np.random.seed(42)\n",
    "\n",
    "# –î–æ–ø–æ–º—ñ–∂–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –¥–ª—è –±—É—Ç—Å—Ç—Ä–∞–ø—É\n",
    "\n",
    "def bootstrap_att_matching(base_df, matched_pairs, outcome_col, B=100):\n",
    "    \"\"\"–ë—É—Ç—Å—Ç—Ä–∞–ø ATT –¥–ª—è matched –≤–∏–±—ñ—Ä–∫–∏ (fixed pairs).\"\"\"\n",
    "    # –°—Ç–≤–æ—Ä—é—î–º–æ dataframe matched\n",
    "    treated_idx = [t for t, c in matched_pairs]\n",
    "    control_idx = [c for t, c in matched_pairs]\n",
    "    df_treated = base_df.loc[treated_idx]\n",
    "    df_control = base_df.loc[control_idx]\n",
    "    \n",
    "    atts = []\n",
    "    n_pairs = len(matched_pairs)\n",
    "    for b in range(B):\n",
    "        # –†–µ—Å–µ–º–ø–ª –ø–∞—Ä –∑ –ø–æ–≤–µ—Ä–Ω–µ–Ω–Ω—è–º\n",
    "        sample_indices = np.random.randint(0, n_pairs, size=n_pairs)\n",
    "        sampled_treated = df_treated.iloc[sample_indices]\n",
    "        sampled_control = df_control.iloc[sample_indices]\n",
    "        att_b = sampled_treated[outcome_col].mean() - sampled_control[outcome_col].mean()\n",
    "        atts.append(att_b)\n",
    "    return np.array(atts)\n",
    "\n",
    "\n",
    "def bootstrap_att_iptw(df_full, outcome_col, weight_col, treatment_col='Treatment', B=100):\n",
    "    \"\"\"–ë—É—Ç—Å—Ç—Ä–∞–ø ATT –¥–ª—è IPTW (—Ä–µ—Å–µ–º–ø–ª —ñ–Ω–¥–µ–∫—Å—ñ–≤ —ñ –ø–µ—Ä–µ–æ—Ü—ñ–Ω–∫–∞ –≤–∞–≥–æ–≤–∏—Ö —Å–µ—Ä–µ–¥–Ω—ñ—Ö).\"\"\"\n",
    "    atts = []\n",
    "    n = len(df_full)\n",
    "    for b in range(B):\n",
    "        sample_idx = np.random.randint(0, n, size=n)\n",
    "        sample = df_full.iloc[sample_idx]\n",
    "        T_b = sample[treatment_col].values\n",
    "        y_b = sample[outcome_col].values\n",
    "        w_b = sample[weight_col].values\n",
    "        treated_mask = (T_b == 1)\n",
    "        control_mask = (T_b == 0)\n",
    "        mean_t = np.sum(y_b[treated_mask] * w_b[treated_mask]) / np.sum(w_b[treated_mask])\n",
    "        mean_c = np.sum(y_b[control_mask] * w_b[control_mask]) / np.sum(w_b[control_mask])\n",
    "        atts.append(mean_t - mean_c)\n",
    "    return np.array(atts)\n",
    "\n",
    "# –û–±—á–∏—Å–ª–µ–Ω–Ω—è –±—É—Ç—Å—Ç—Ä–∞–ø-–î–Ü –¥–ª—è –æ–±–æ—Ö –º–µ—Ç–æ–¥—ñ–≤\n",
    "bootstrap_results = []\n",
    "\n",
    "for outcome in ['Retention_7d', 'Retention_30d']:\n",
    "    # Matching 1\n",
    "    atts_match1 = bootstrap_att_matching(df_psm_matched1, matched_pairs_1, outcome, B=B)\n",
    "    ci_l_m1, ci_u_m1 = np.percentile(atts_match1, [2.5, 97.5])\n",
    "    # Matching 2\n",
    "    atts_match2 = bootstrap_att_matching(df_psm_matched1, matched_pairs_2, outcome, B=B)\n",
    "    ci_l_m2, ci_u_m2 = np.percentile(atts_match2, [2.5, 97.5])\n",
    "    \n",
    "    # IPTW\n",
    "    atts_iptw = bootstrap_att_iptw(df_psm, outcome, 'iptw_weight_winsor', B=B)\n",
    "    ci_l_w, ci_u_w = np.percentile(atts_iptw, [2.5, 97.5])\n",
    "    \n",
    "    bootstrap_results.append({\n",
    "        'Outcome': outcome,\n",
    "        'Method': 'Matching 0.2√óSD',\n",
    "        'Boot ATT (–ø.–ø.)': atts_match1.mean() * 100,\n",
    "        'CI Low (–ø.–ø.)': ci_l_m1 * 100,\n",
    "        'CI High (–ø.–ø.)': ci_u_m1 * 100\n",
    "    })\n",
    "    bootstrap_results.append({\n",
    "        'Outcome': outcome,\n",
    "        'Method': 'Matching 0.05',\n",
    "        'Boot ATT (–ø.–ø.)': atts_match2.mean() * 100,\n",
    "        'CI Low (–ø.–ø.)': ci_l_m2 * 100,\n",
    "        'CI High (–ø.–ø.)': ci_u_m2 * 100\n",
    "    })\n",
    "    bootstrap_results.append({\n",
    "        'Outcome': outcome,\n",
    "        'Method': 'IPTW',\n",
    "        'Boot ATT (–ø.–ø.)': atts_iptw.mean() * 100,\n",
    "        'CI Low (–ø.–ø.)': ci_l_w * 100,\n",
    "        'CI High (–ø.–ø.)': ci_u_w * 100\n",
    "    })\n",
    "\n",
    "bootstrap_df = pd.DataFrame(bootstrap_results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"–ë–£–¢–°–¢–†–ê–ü –î–Ü –î–õ–Ø ATT\")\n",
    "print(\"=\"*80)\n",
    "print(bootstrap_df.to_string(index=False, formatters={'Boot ATT (–ø.–ø.)': '{:.2f}'.format, 'CI Low (–ø.–ø.)': '{:.2f}'.format, 'CI High (–ø.–ø.)': '{:.2f}'.format}))\n",
    "\n",
    "# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —ñ–Ω—Ç–µ—Ä–≤–∞–ª—ñ–≤\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i, row in bootstrap_df.iterrows():\n",
    "    ax.plot([row['CI Low (–ø.–ø.)'], row['CI High (–ø.–ø.)']], [i, i], color='#2c3e50', linewidth=3)\n",
    "    ax.scatter(row['Boot ATT (–ø.–ø.)'], i, color='#e74c3c', s=100, zorder=5)\n",
    "    ax.text(row['CI High (–ø.–ø.)'] + 0.5, i, f\"{row['Boot ATT (–ø.–ø.)']:.2f} –ø.–ø.\", va='center')\n",
    "\n",
    "ax.set_yticks(range(len(bootstrap_df)))\n",
    "ax.set_yticklabels(bootstrap_df['Outcome'] + ' | ' + bootstrap_df['Method'])\n",
    "ax.set_xlabel('ATT (–ø.–ø.)')\n",
    "ax.set_title('–ë—É—Ç—Å—Ç—Ä–∞–ø 95% –¥–æ–≤—ñ—Ä—á—ñ —ñ–Ω—Ç–µ—Ä–≤–∞–ª–∏ –¥–ª—è ATT')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì –ë—É—Ç—Å—Ç—Ä–∞–ø-–î–Ü —Ä–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω–æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671f73bf",
   "metadata": {},
   "source": [
    "## –í–∏—Å–Ω–æ–≤–∫–∏ —Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó (—É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§–æ—Ä–º—É–≤–∞–Ω–Ω—è —Ñ—ñ–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –≤–∏—Å–Ω–æ–≤–∫—É\n",
    "print(\"=\"*80)\n",
    "print(\"–§–Ü–ù–ê–õ–¨–ù–Ü –í–ò–°–ù–û–í–ö–ò\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_lines = []\n",
    "\n",
    "# –î–æ–¥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∫–æ—Ä–µ–ª—è—Ü—ñ–π (–∑–±–µ—Ä–µ–∂–µ–Ω—ñ —Ä–∞–Ω—ñ—à–µ)\n",
    "summary_lines.append(\"1. –ö–æ—Ä–µ–ª—è—Ü—ñ–π–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –ø–æ–∫–∞–∑–∞–≤ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –∞—Å–æ—Ü—ñ–∞—Ü—ñ—ó –º—ñ–∂ Treatment —ñ —É—Ç—Ä–∏–º–∞–Ω–Ω—è–º, –∞–ª–µ —Ü–µ –ù–ï —î –¥–æ–∫–∞–∑–æ–º –ø—Ä–∏—á–∏–Ω–Ω–æ—Å—Ç—ñ —á–µ—Ä–µ–∑ –º–æ–∂–ª–∏–≤—ñ –∑–º—ñ—à—É–≤–∞—á—ñ.\")\n",
    "\n",
    "# –î–æ–¥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ t-—Ç–µ—Å—Ç—ñ–≤\n",
    "summary_lines.append(\"2. RCT-–ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è (—è–∫—â–æ —Ä–∞–Ω–¥–æ–º—ñ–∑–∞—Ü—ñ—è –±—É–ª–∞ –∫–æ—Ä–µ–∫—Ç–Ω–æ—é) –¥–∞—î –ø–µ—Ä–≤–∏–Ω–Ω—ñ –¥–æ–∫–∞–∑–∏ –µ—Ñ–µ–∫—Ç—É —Ñ—É–Ω–∫—Ü—ñ—ó. –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ t-—Ç–µ—Å—Ç—ñ–≤ —Å–ª—ñ–¥ —Ç–ª—É–º–∞—á–∏—Ç–∏ –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –ø—Ä–∏–ø—É—â–µ–Ω–Ω—è –ø—Ä–æ —Å–ø—Ä–∞–≤–∂–Ω—é –≤–∏–ø–∞–¥–∫–æ–≤—ñ—Å—Ç—å.\")\n",
    "\n",
    "# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ø—ñ–¥—Ö–æ–¥—ñ–≤ matching —Ç–∞ IPTW\n",
    "summary_lines.append(\"3. PSM –¥–æ–∑–≤–æ–ª–∏–≤ –∑–º–µ–Ω—à–∏—Ç–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å –º—ñ–∂ –≥—Ä—É–ø–∞–º–∏ –∑–∞ Avg_Session_Time —Ç–∞ Region. –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –¥–≤–æ—Ö caliper-–ø–æ—Ä–æ–≥—ñ–≤ –ø–æ–∫–∞–∑–∞–ª–æ trade-off –º—ñ–∂ –∫—ñ–ª—å–∫—ñ—Å—Ç—é –∑—ñ—Å—Ç–∞–≤–ª–µ–Ω–∏—Ö –ø–∞—Ä —ñ —è–∫—ñ—Å—Ç—é –±–∞–ª–∞–Ω—Å—É.\")\n",
    "summary_lines.append(\"4. IPTW —Å—Ç–∞–±—ñ–ª—ñ–∑—É–≤–∞–≤ –≤–∞–≥–∏ —ñ –∑–∞–±–µ–∑–ø–µ—á–∏–≤ –¥–æ–¥–∞—Ç–∫–æ–≤—É –æ—Ü—ñ–Ω–∫—É ATT, —â–æ —É–∑–≥–æ–¥–∂—É—î—Ç—å—Å—è –∑–∞ –Ω–∞–ø—Ä—è–º–∫–æ–º —ñ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ matching.\")\n",
    "\n",
    "# –Ø–∫—â–æ —î –±—É—Ç—Å—Ç—Ä–∞–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏\n",
    "if 'bootstrap_df' in globals():\n",
    "    summary_lines.append(\"5. –ë—É—Ç—Å—Ç—Ä–∞–ø-–¥–æ–≤—ñ—Ä—á—ñ —ñ–Ω—Ç–µ—Ä–≤–∞–ª–∏ –¥–ª—è ATT –ø–æ–∫–∞–∑–∞–ª–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω—É –Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω—ñ—Å—Ç—å –æ—Ü—ñ–Ω–æ–∫. –Ü–Ω—Ç–µ—Ä–≤–∞–ª–∏ –Ω–µ —î –Ω–∞–¥—Ç–æ —à–∏—Ä–æ–∫–∏–º–∏, —â–æ —Å–≤—ñ–¥—á–∏—Ç—å –ø—Ä–æ –≤—ñ–¥–Ω–æ—Å–Ω—É —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å –µ—Ñ–µ–∫—Ç—É.\")\n",
    "\n",
    "# –í–∑–∞—î–º–æ–¥—ñ—è\n",
    "if 'needs_interaction' in globals() and needs_interaction:\n",
    "    summary_lines.append(\"6. –î–æ–¥–∞–≤–∞–Ω–Ω—è –≤–∑–∞—î–º–æ–¥—ñ—ó Region√óSession —É doubly-robust –º–æ–¥–µ–ª—è—Ö —É—Ç–æ—á–Ω–∏–ª–æ –æ—Ü—ñ–Ω–∫—É Treatment —ñ —á–∞—Å—Ç–∫–æ–≤–æ –∫–æ–º–ø–µ–Ω—Å—É–≤–∞–ª–æ –∑–∞–ª–∏—à–∫–æ–≤–∏–π –¥–∏—Å–±–∞–ª–∞–Ω—Å.\")\n",
    "else:\n",
    "    summary_lines.append(\"6. –í–∑–∞—î–º–æ–¥—ñ—è Region√óSession –Ω–µ –±—É–ª–∞ –ø–æ—Ç—Ä—ñ–±–Ω–∞ ‚Äî –±–∞–ª–∞–Ω—Å –¥–æ—Å—è–≥–Ω—É—Ç–æ –±–µ–∑ —ó—ó –≤–∫–ª—é—á–µ–Ω–Ω—è.\")\n",
    "\n",
    "# –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó\n",
    "summary_lines.append(\"7. –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á: \\n   ‚Ä¢ –ú–æ–∂–Ω–∞ —Ä–æ–∑–≥–ª—è–¥–∞—Ç–∏ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ—ó, —è–∫—â–æ –ø—Ä–∞–∫—Ç–∏—á–Ω–∏–π –µ—Ñ–µ–∫—Ç (ATT) –¥–æ—Å—Ç–∞—Ç–Ω—ñ–π –∑ –±—ñ–∑–Ω–µ—Å-—Ç–æ—á–∫–∏ –∑–æ—Ä—É.\\n   ‚Ä¢ –ü—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª—ñ–∑ –≥–µ—Ç–µ—Ä–æ–≥–µ–Ω–Ω–æ—Å—Ç—ñ –µ—Ñ–µ–∫—Ç—É –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ö (—Ä–µ–≥—ñ–æ–Ω, —á–∞—Å —Å–µ—Å—ñ—ó).\\n   ‚Ä¢ –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –¥–æ–≤–≥–æ—Å—Ç—Ä–æ–∫–æ–≤–∏–π –≤–ø–ª–∏–≤ (60d, 90d retention).\\n   ‚Ä¢ –û—Ü—ñ–Ω–∏—Ç–∏ –≤—Ç–æ—Ä–∏–Ω–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ (–∫–æ–Ω–≤–µ—Ä—Å—ñ—è –≤ –æ–ø–ª–∞—Ç—É, –∑–∞–≤–µ—Ä—à–µ–Ω—ñ —É—Ä–æ–∫–∏).\")\n",
    "\n",
    "# –û–±–º–µ–∂–µ–Ω–Ω—è\n",
    "summary_lines.append(\"8. –û–ë–ú–ï–ñ–ï–ù–ù–Ø: \\n   ‚Ä¢ PSM –∫–æ–Ω—Ç—Ä–æ–ª—é—î –ª–∏—à–µ –∑–∞ —Å–ø–æ—Å—Ç–µ—Ä–µ–∂—É–≤–∞–Ω–∏–º–∏ –∫–æ–≤–∞—Ä —ñ–∞—Ç–∞–º–∏ ‚Äî –Ω–µ–≤–∏–º—ñ—Ä—è–Ω—ñ —Ñ–∞–∫—Ç–æ—Ä–∏ –º–æ–∂—É—Ç—å —Å–ø—Ä–∏—á–∏–Ω–∏—Ç–∏ –∑–∞–ª–∏—à–∫–æ–≤–µ –∑–º—ñ—â–µ–Ω–Ω—è.\\n   ‚Ä¢ –†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ —è–∫–æ—Å—Ç—ñ –º–æ–¥–µ–ª—ñ —Å—Ö–∏–ª—å–Ω–æ—Å—Ç—ñ (–ª–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è).\\n   ‚Ä¢ –ë—É—Ç—Å—Ç—Ä–∞–ø –¥–∞—î –Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω—ñ—Å—Ç—å, –∞–ª–µ –Ω–µ —É—Å—É–≤–∞—î —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–Ω–µ –∑–º—ñ—â–µ–Ω–Ω—è.\\n   ‚Ä¢ –Ø–∫—â–æ —Ä–µ–∞–ª—å–Ω–∞ —Ä–∞–Ω–¥–æ–º—ñ–∑–∞—Ü—ñ—è –ø–æ—Ä—É—à–µ–Ω–∞ ‚Äî –æ—Ü—ñ–Ω–∫–∏ RCT —Ç–∞ PSM –º–æ–∂—É—Ç—å –±—É—Ç–∏ –∑–º—ñ—â–µ–Ω–∏–º–∏.\")\n",
    "\n",
    "# –ü—ñ–¥—Å—É–º–æ–∫\n",
    "summary_lines.append(\"9. –ü–Ü–î–°–£–ú–û–ö: \\n   ‚Ä¢ –£—Å—ñ —Ç—Ä–∏ –ø—ñ–¥—Ö–æ–¥–∏ (RCT, Matching, IPTW) –¥–∞—é—Ç—å —É–∑–≥–æ–¥–∂–µ–Ω—É –∫–∞—Ä—Ç–∏–Ω—É: —Ñ—É–Ω–∫—Ü—ñ—è –º–∞—î –ø–æ–∑–∏—Ç–∏–≤–Ω–∏–π –≤–ø–ª–∏–≤ –Ω–∞ —É—Ç—Ä–∏–º–∞–Ω–Ω—è.\\n   ‚Ä¢ –í–µ–ª–∏—á–∏–Ω–∞ –µ—Ñ–µ–∫—Ç—É –ø–æ–≤–∏–Ω–Ω–∞ –±—É—Ç–∏ —Å–ø—ñ–≤—Å—Ç–∞–≤–ª–µ–Ω–∞ –∑ –≤–∞—Ä—Ç—ñ—Å—Ç—é –≤–ø—Ä–æ–≤–∞–¥–∂–µ–Ω–Ω—è —Ç–∞ –æ—á—ñ–∫—É–≤–∞–Ω–∏–º LTV.\\n   ‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥—É—î—Ç—å—Å—è –ø—Ä–æ–¥–æ–≤–∂–∏—Ç–∏ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –¥–ª—è –¥–æ–≤–≥–æ—Å—Ç—Ä–æ–∫–æ–≤–∏—Ö –º–µ—Ç—Ä–∏–∫ —Ç–∞ –ø—Ä–æ–≤–µ—Å—Ç–∏ A/B —Ç–µ—Å—Ç –Ω–∞ –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–∞—Ö.\")\n",
    "\n",
    "final_summary = \"\\n\\n\".join(summary_lines)\n",
    "print(final_summary)\n",
    "\n",
    "# –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —É CSV\n",
    "att_df.to_csv('goit_pa_hm_8/att_matching_results.csv', index=False)\n",
    "bootstrap_df.to_csv('goit_pa_hm_8/att_bootstrap_results.csv', index=False)\n",
    "weighted_balance_df.to_csv('goit_pa_hm_8/iptw_balance.csv', index=False)\n",
    "balance_before.to_csv('goit_pa_hm_8/balance_before.csv', index=False)\n",
    "balance_after_1.to_csv('goit_pa_hm_8/balance_after_matching_caliper_sd.csv', index=False)\n",
    "balance_after_2.to_csv('goit_pa_hm_8/balance_after_matching_fixed.csv', index=False)\n",
    "\n",
    "print(\"\\n‚úì –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É CSV —Ñ–∞–π–ª–∏ –≤ –ø–∞–ø—Ü—ñ goit_pa_hm_8/\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
